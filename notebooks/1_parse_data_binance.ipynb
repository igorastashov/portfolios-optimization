{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1006a6b0-fd35-46d3-81b2-1de998c61f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "import statsmodels.api as sm\n",
    "import sktime\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.utils.plotting import plot_series\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50fd2ae-2f2d-4bf1-86ac-8487257a2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm  # Импортируем tqdm для отображения прогресса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2eaf3e-1ff5-4321-944c-f40f27dde32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4275665-e022-4258-b8be-5121cdc945b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from binance.spot import Spot\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bd176a-a99a-4d36-873b-75cf4b16762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d777e0-92db-497d-91e5-204c741ce2e9",
   "metadata": {},
   "source": [
    "## API Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2424026a-4a16-4215-913d-582e93ee702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance import Client\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Инициализация клиента Binance\n",
    "api_key = 'tjdQdCndNjOY2bQeS8Eh0KITPv5IY7XX9rw06qEIx7G4tufDwjFAATTTn9AIMQZE'\n",
    "api_secret = 'ZsqZ7c5uwOdrrWBxjkIIYkP3vjKYpPCUAdbP0oY2RHm39pAIEijCzfoIkTccBReF' \n",
    "client = Client(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a6e142-422f-4c34-bbb9-ecad097cc381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения исторических данных\n",
    "def fetch_hourly_data(symbol, interval, start_time, end_time=None):\n",
    "    \"\"\"\n",
    "    Получает исторические klines (свечи) для указанного символа и временного интервала.\n",
    "    \n",
    "    :param symbol: Символ торговой пары (например, \"BTCUSDT\")\n",
    "    :param interval: Интервал свечей (например, \"1h\" для почасовых данных)\n",
    "    :param start_time: Начало периода в формате строки (например, \"1 Jan, 2023\")\n",
    "    :param end_time: Конец периода в формате строки (если None, то используется текущее время)\n",
    "    :return: DataFrame с данными\n",
    "    \"\"\"\n",
    "    # Получение данных через API\n",
    "    klines = client.get_historical_klines(\n",
    "        symbol=symbol,\n",
    "        interval=interval,\n",
    "        start_str=start_time,\n",
    "        end_str=end_time\n",
    "    )\n",
    "    \n",
    "    # Преобразование данных в DataFrame\n",
    "    columns = [\n",
    "        'Open time', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "        'Close time', 'Quote asset volume', 'Number of trades',\n",
    "        'Taker buy base asset volume', 'Taker buy quote asset volume', 'Ignore'\n",
    "    ]\n",
    "    df = pd.DataFrame(klines, columns=columns)\n",
    "    \n",
    "    # Преобразование типов данных\n",
    "    df['Open time'] = pd.to_datetime(df['Open time'], unit='ms')\n",
    "    df['Close time'] = pd.to_datetime(df['Close time'], unit='ms')\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317aacb7-c5e8-4114-80af-46025649780b",
   "metadata": {},
   "source": [
    "## Парсинг активов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb0f825-9054-4b7f-b540-a467746b7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"BNBUSDT\", \"BTCUSDT\", \"CAKEUSDT\", \"ETHUSDT\",\n",
    "           \"LTCUSDT\", \"SOLUSDT\", \"STRKUSDT\", \"TONUSDT\",\n",
    "           \"USDCUSDT\", \"XRPUSDT\", \"PEPEUSDT\",\n",
    "           \"HBARUSDT\", \"APTUSDT\", \"LDOUSDT\", \"JUPUSDT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8ec449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Создание папки data в корне, если она не существует\n",
    "data_dir = \"../data\"  # Относительный путь к папке data из notebooks\n",
    "os.makedirs(data_dir, exist_ok=True)  # Создаем папку, если её нет\n",
    "\n",
    "# Параметры запроса\n",
    "interval = Client.KLINE_INTERVAL_1HOUR  # Почасовые данные\n",
    "start_time = \"1 Jan, 2021\"  # Начало периода\n",
    "end_time = None  # До текущего времени\n",
    "\n",
    "# # Цикл для обработки каждой торговой пары\n",
    "# for symbol in tqdm(symbols, desc=\"Обработка символов\", unit=\"symbol\"):\n",
    "#     try:\n",
    "#         # Получение данных\n",
    "#         hourly_data = fetch_hourly_data(symbol, interval, start_time, end_time)\n",
    "\n",
    "#         # Сохранение данных в CSV файл в папку data\n",
    "#         output_file = os.path.join(data_dir, f\"{symbol}_hourly_data.csv\")  # Полный путь к файлу\n",
    "#         hourly_data.to_csv(output_file, index=False)\n",
    "\n",
    "#         print(f\"Данные для {symbol} успешно сохранены в файл: {output_file}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Ошибка при обработке {symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Функция для получения последней даты из CSV файла\n",
    "def get_last_date_from_csv(file_path):\n",
    "    try:\n",
    "        # Читаем только первую и последнюю строку файла для определения последней даты\n",
    "        df = pd.read_csv(file_path, usecols=[\"Open time\"], parse_dates=[\"Open time\"])\n",
    "        last_date = df[\"Open time\"].iloc[-1]\n",
    "        return last_date\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Цикл для обработки всех CSV файлов\n",
    "for file_name in tqdm(os.listdir(data_dir), desc=\"Обновление данных\", unit=\"file\"):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        symbol = file_name.split(\"_\")[0]  # Получаем символ из имени файла (например, BTCUSDT)\n",
    "\n",
    "        # Получаем последнюю дату из файла\n",
    "        last_date = get_last_date_from_csv(file_path)\n",
    "        if last_date is None:\n",
    "            print(f\"Пропуск файла {file_name}: не удалось определить последнюю дату.\")\n",
    "            continue\n",
    "\n",
    "        # Устанавливаем начало периода для запроса новых данных\n",
    "        start_time = last_date.strftime(\"%d %b, %Y %H:%M:%S\")  # Преобразуем дату в строку\n",
    "        end_time = None  # До текущего времени\n",
    "\n",
    "        try:\n",
    "            # Получение новых данных\n",
    "            new_data = fetch_hourly_data(symbol, interval, start_time, end_time)\n",
    "\n",
    "            if new_data.empty:\n",
    "                print(f\"Нет новых данных для {symbol}.\")\n",
    "                continue\n",
    "\n",
    "            # Удаляем первую строку новых данных, так как она может дублировать последнюю строку старых данных\n",
    "            new_data = new_data.iloc[1:]\n",
    "\n",
    "            if not new_data.empty:\n",
    "                # Добавляем новые данные в существующий CSV файл\n",
    "                with open(file_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                    new_data.to_csv(f, header=False, index=False)\n",
    "\n",
    "                print(f\"Файл {file_name} успешно обновлен новыми данными.\")\n",
    "            else:\n",
    "                print(f\"Нет новых данных для добавления в файл {file_name}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обновлении данных для {symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346973b-f417-4bcb-b1c9-c9daf30c4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# Создаем пустой DataFrame для объединения данных\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Оборачиваем symbols в tqdm для отображения прогресса\n",
    "for symbol in tqdm(symbols, desc=\"Обработка символов\", unit=\"symbol\"):\n",
    "    csv_file = os.path.join(data_dir, f\"{symbol}_hourly_data.csv\")  # Полный путь к CSV файлу\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"Файл {csv_file} не найден. Пропускаем символ {symbol}.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Читаем данные из файла\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['Close time'] = pd.to_datetime(df['Close time'])  # Преобразуем 'Close time' в datetime\n",
    "        df = df[['Close time', 'Close']]  # Оставляем только нужные колонки\n",
    "        df.rename(columns={'Close': symbol}, inplace=True)  # Переименовываем колонку 'Close' в название символа\n",
    "        df.set_index('Close time', inplace=True)  # Устанавливаем 'Close time' как индекс\n",
    "\n",
    "        # Объединяем данные\n",
    "        if combined_data.empty:\n",
    "            combined_data = df\n",
    "        else:\n",
    "            combined_data = combined_data.join(df, how='outer')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке файла {csv_file}: {e}\")\n",
    "\n",
    "# Заполняем пропущенные значения методом forward fill\n",
    "if not combined_data.empty:\n",
    "    combined_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Сохраняем объединенные данные в CSV-файл в папку data\n",
    "output_file = os.path.join(data_dir, \"data_compare_eda.csv\")  # Полный путь к выходному файлу\n",
    "combined_data.to_csv(output_file)\n",
    "\n",
    "print(f\"Объединенные данные успешно сохранены в файл: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afab8fc-2824-4697-bcf6-bbd50bb407e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6aa6a-d60c-4d82-a097-640dfa8fe5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e71b3-4291-4962-9b5c-5674ff48e409",
   "metadata": {},
   "source": [
    "## Визуализация активов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb9bbb-4ed2-412c-a8f8-118bce26cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the number of rows and columns for the grid\n",
    "num_columns = len(combined_data.columns)\n",
    "rows = (num_columns + 2) // 3  # Ensure enough rows for 3 columns per row\n",
    "cols = 3\n",
    "\n",
    "plt.figure(figsize=(18, 6 * rows))  # Adjust figure size dynamically\n",
    "plt.subplots_adjust(top=1)\n",
    "\n",
    "for i, company in enumerate(combined_data.columns, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    combined_data[company].plot()\n",
    "    plt.xlabel(None)\n",
    "    plt.title(company)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9c76d-622d-48cf-a3f6-c719ee3be727",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd0689-e114-4500-8a86-a8476b45971d",
   "metadata": {},
   "source": [
    "## Визуализация нормализованных активов за последние N дней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f0a72-e423-4d69-a206-9cc5949b13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_days = 120\n",
    "\n",
    "# Определяем количество записей за последние 120 дней (120 дней * 24 часа)\n",
    "last_120_days_records = N_days * 24\n",
    "\n",
    "# Выбираем последние 2880 записей (последние 120 дней)\n",
    "recent_data = combined_data.tail(last_120_days_records)\n",
    "\n",
    "# Нормализуем данные за последние 120 дней\n",
    "normalized_recent_data = (\n",
    "    recent_data.drop([\"USDCUSDT\"], axis=1) - \n",
    "    recent_data.drop([\"USDCUSDT\"], axis=1).mean()\n",
    ") / recent_data.drop([\"USDCUSDT\"], axis=1).std()\n",
    "\n",
    "# Строим график\n",
    "plt.figure(figsize=(14, 7))\n",
    "for column in normalized_recent_data.columns:\n",
    "    plt.plot(normalized_recent_data.index, normalized_recent_data[column], label=column)\n",
    "\n",
    "plt.title(\"Normalized Close Prices of Cryptocurrencies (Last 120 Days)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Normalized Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b20e1-68ed-408e-b2ad-3ff5fc8b7e13",
   "metadata": {},
   "source": [
    "## Визуализация нормализованных активов за все время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b435875-3807-4c63-b9a3-33cb28136212",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (combined_data.drop([\"USDCUSDT\"], axis=1) - combined_data.drop([\"USDCUSDT\"], axis=1).mean()) / combined_data.drop([\"USDCUSDT\"], axis=1).std()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for column in normalized_data.columns:\n",
    "    plt.plot(normalized_data.index, normalized_data[column], label=column)\n",
    "\n",
    "plt.title(\"Normalized Close Prices of Cryptocurrencies\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Normalized Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e736e4-4719-4ab5-a451-6292e0c1a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Создаем box plot для нормализованных данных\n",
    "fig = px.box(normalized_data, \n",
    "             title=\"Box Plot of Normalized Cryptocurrency Prices (Weekly Data)\",\n",
    "             labels={\"value\": \"Normalized Price\", \"variable\": \"Cryptocurrency\"},\n",
    "             template=\"plotly_white\")\n",
    "\n",
    "# Настройка внешнего вида\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,  # ширина графика\n",
    "    height=400,  # высота графика\n",
    "    margin=dict(l=50, r=50, b=50, t=50, pad=4),\n",
    "    font=dict(size=12),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Отображаем график\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505f5b2-dbe7-4ddd-9746-ce7f7653c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e04d2-3d2c-4c1a-9bbc-164c02287065",
   "metadata": {},
   "source": [
    "## Оценим распределения активов по неделям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88234ad2-6fb8-43d0-9ece-8d0992541df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем начальную дату\n",
    "start_date = \"2023-01-01\"\n",
    "\n",
    "# Выбираем данные, начиная с 2023-01-01\n",
    "filtered_data = combined_data.loc[start_date:]\n",
    "filtered_data = filtered_data[~filtered_data.index.duplicated(keep='last')]\n",
    "\n",
    "# Ресемплируем данные по неделям и заполняем пропуски методом forward fill\n",
    "weekly_data = filtered_data.drop([\"USDCUSDT\"], axis=1).resample('W').ffill()\n",
    "\n",
    "# Рассчитываем процентные изменения для недельных данных\n",
    "weekly_pct_change = weekly_data.pct_change()\n",
    "\n",
    "# Фильтруем активы, у которых есть хотя бы несколько значений (исключаем активы без достаточных данных)\n",
    "min_valid_values = 2  # Минимальное количество значений для анализа\n",
    "valid_assets = weekly_pct_change.columns[weekly_pct_change.count() >= min_valid_values]\n",
    "weekly_pct_change = weekly_pct_change[valid_assets]\n",
    "\n",
    "# Строим гистограмму распределения недельных процентных изменений\n",
    "weekly_pct_change.plot.hist(stacked=True, bins=40, figsize=(12, 8), alpha=0.7, grid=True)\n",
    "\n",
    "# Настройка графика\n",
    "plt.title(\"Distribution of Weekly Percentage Changes (From 2023-01-01)\", fontsize=16)\n",
    "plt.xlabel(\"Weekly Percentage Change\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f184e-952e-45ee-b76c-06250e46657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_pct_change.plot.bar(stacked=True, figsize=(21, 8))\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e73b29-eb33-4b19-a8ea-f3d1e818fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pct_m = weekly_pct_change.corr()\n",
    "\n",
    "styled_corr = (\n",
    "    corr_pct_m.style\n",
    "    .background_gradient(cmap='coolwarm') \n",
    "    .format(\"{:.2f}\")                  \n",
    ")\n",
    "\n",
    "display(styled_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15638900-f7f7-4441-a0de-195d883bd125",
   "metadata": {},
   "source": [
    "## Обор активов с минимальной корреляцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b028ea2-0dc8-4ef0-8883-8377f6039ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Предположим, что weekly_pct_change — это DataFrame с недельными процентными изменениями\n",
    "corr_pct_m = weekly_pct_change.corr()\n",
    "\n",
    "# Преобразуем матрицу корреляций в формат длинной таблицы\n",
    "corr_long = (\n",
    "    corr_pct_m\n",
    "    .reset_index()  # Добавляем индекс как столбец\n",
    "    .melt(id_vars=\"index\", var_name=\"Asset2\", value_name=\"Correlation\")  # Преобразуем в длинный формат\n",
    "    .rename(columns={\"index\": \"Asset1\"})  # Переименовываем столбец\n",
    ")\n",
    "\n",
    "# Удаляем дубликаты и диагональные значения (где Asset1 == Asset2)\n",
    "corr_long = corr_long[\n",
    "    (corr_long[\"Asset1\"] != corr_long[\"Asset2\"])  # Исключаем диагональ\n",
    "].drop_duplicates(subset=[\"Correlation\"])  # Удаляем дубликаты (если есть)\n",
    "\n",
    "# Сортируем по возрастанию корреляции\n",
    "corr_sorted = corr_long.sort_values(by=\"Correlation\", ascending=True)\n",
    "\n",
    "# Если хотите стилизовать результат:\n",
    "styled_corr_sorted = (\n",
    "    corr_sorted.style\n",
    "    .background_gradient(cmap='coolwarm', subset=[\"Correlation\"])  # Градиент для столбца Correlation\n",
    "    .format({\"Correlation\": \"{:.2f}\"})  # Форматирование значений корреляции\n",
    ")\n",
    "\n",
    "display(styled_corr_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75d907-e19d-48e1-962e-dcb1f1635745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Предположим, что corr_sorted уже создан и содержит отсортированные пары активов\n",
    "# corr_sorted = corr_long.sort_values(by=\"Correlation\", ascending=True)\n",
    "\n",
    "def select_portfolio(corr_sorted, max_assets=5):\n",
    "    portfolio = []  # Список выбранных активов\n",
    "    used_assets = set()  # Множество для отслеживания уже добавленных активов\n",
    "    \n",
    "    for _, row in corr_sorted.iterrows():\n",
    "        asset1, asset2, correlation = row[\"Asset1\"], row[\"Asset2\"], row[\"Correlation\"]\n",
    "        \n",
    "        # Если оба актива еще не в портфеле, добавляем их\n",
    "        if len(portfolio) == 0:\n",
    "            # Первые два актива всегда добавляем\n",
    "            portfolio.append(asset1)\n",
    "            portfolio.append(asset2)\n",
    "            used_assets.update([asset1, asset2])\n",
    "        elif asset1 not in used_assets and asset2 not in used_assets:\n",
    "            # Проверяем корреляцию нового актива со всеми активами в портфеле\n",
    "            avg_corr = sum(\n",
    "                corr_sorted.loc[\n",
    "                    (corr_sorted[\"Asset1\"] == asset1) & (corr_sorted[\"Asset2\"].isin(portfolio)), \"Correlation\"\n",
    "                ].tolist()\n",
    "            ) / len(portfolio)\n",
    "            \n",
    "            if avg_corr < 0.5:  # Добавляем только если средняя корреляция ниже порога\n",
    "                portfolio.append(asset1)\n",
    "                used_assets.add(asset1)\n",
    "        \n",
    "        # Останавливаемся, если достигли максимального количества активов\n",
    "        if len(portfolio) >= max_assets:\n",
    "            break\n",
    "    \n",
    "    return portfolio\n",
    "\n",
    "# Выбор портфеля\n",
    "selected_portfolio = select_portfolio(corr_sorted, max_assets=7)\n",
    "print(\"Selected Portfolio:\", selected_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d85658-7b5f-4a9a-97e0-e79e2ff808d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем начальную дату\n",
    "start_date = \"2023-01-01\"\n",
    "\n",
    "# Выбираем данные, начиная с 2023-01-01\n",
    "filtered_data = combined_data.loc[start_date:]\n",
    "filtered_data = filtered_data[~filtered_data.index.duplicated(keep='last')]\n",
    "\n",
    "# Ресемплируем данные по неделям и заполняем пропуски методом forward fill\n",
    "weekly_data = filtered_data[selected_portfolio].resample('W').ffill()\n",
    "\n",
    "# Рассчитываем процентные изменения для недельных данных\n",
    "weekly_pct_change = weekly_data.pct_change()\n",
    "\n",
    "# Фильтруем активы, у которых есть хотя бы несколько значений (исключаем активы без достаточных данных)\n",
    "min_valid_values = 2  # Минимальное количество значений для анализа\n",
    "valid_assets = weekly_pct_change.columns[weekly_pct_change.count() >= min_valid_values]\n",
    "weekly_pct_change = weekly_pct_change[valid_assets]\n",
    "\n",
    "# Строим гистограмму распределения недельных процентных изменений\n",
    "weekly_pct_change.plot.hist(stacked=True, bins=40, figsize=(12, 8), alpha=0.7, grid=True)\n",
    "\n",
    "# Настройка графика\n",
    "plt.title(\"Distribution of Weekly Percentage Changes (From 2023-01-01)\", fontsize=16)\n",
    "plt.xlabel(\"Weekly Percentage Change\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84401b63-5299-4869-be85-202d4d4d46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_pct_change.plot.bar(stacked=True, figsize=(21, 8))\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0f982-e41c-4efe-aecb-23c0b8589e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pct_m = weekly_pct_change.corr()\n",
    "\n",
    "styled_corr = (\n",
    "    corr_pct_m.style\n",
    "    .background_gradient(cmap='coolwarm') \n",
    "    .format(\"{:.2f}\")                  \n",
    ")\n",
    "\n",
    "display(styled_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e23fd5-6277-49e6-b9bd-9974d164dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc799880-7bf3-464d-b3a0-5230f1f601bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_portfolio.remove('HBARUSDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865ca95-979b-458c-9065-0cd4ae3d7bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Настройка стиля графиков\n",
    "register_matplotlib_converters()\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rc(\"figure\", figsize=(12, 8))\n",
    "plt.rc(\"font\", size=13)\n",
    "\n",
    "# Агрегация данных: усреднение по неделям\n",
    "weekly_data = combined_data[selected_portfolio].resample('W').mean()\n",
    "\n",
    "# Определяем начальную дату\n",
    "start_date = \"2023-01-01\"\n",
    "\n",
    "# Фильтрация данных, начиная с start_date\n",
    "filtered_data = weekly_data.loc[start_date:]\n",
    "\n",
    "# Применение STL-декомпозиции для каждой криптовалюты\n",
    "for asset in filtered_data.columns:\n",
    "    # Проверяем, что у актива есть достаточное количество данных\n",
    "    if filtered_data[asset].count() >= 7:  # Минимум 7 точек для декомпозиции\n",
    "        # Создание и обучение STL-модели\n",
    "        stlModel = STL(filtered_data[asset].dropna(), robust=True, period=7).fit()  # period=7 для недельной сезонности\n",
    "        \n",
    "        # Вывод названия актива\n",
    "        print(f\"STL Decomposition for {asset}\")\n",
    "        \n",
    "        # Построение графика (без observed и resid компонент)\n",
    "        fig = stlModel.plot(observed=False, resid=False)\n",
    "        plt.show()\n",
    "        \n",
    "        # Получение остатков из STL-модели\n",
    "        residuals = stlModel.resid\n",
    "        \n",
    "        # Построение графика остатков\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(residuals, label=\"Residuals\", color=\"gray\", alpha=0.7)\n",
    "        plt.title(f\"Residuals from STL Decomposition ({asset})\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Residual Value\")\n",
    "        plt.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)  # Линия для нулевых остатков\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        # График автокорреляции остатков\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plot_acf(residuals.dropna(), lags=30, ax=plt.gca())  # Убираем NaN перед построением ACF\n",
    "        plt.title(f\"Autocorrelation of Residuals ({asset})\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Not enough data for {asset} to perform STL decomposition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8ee86-fabc-4d4e-b89d-f634762502a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Настройка стиля графиков\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rc(\"figure\", figsize=(18, 12))\n",
    "plt.rc(\"font\", size=12)\n",
    "\n",
    "# Функция для построения графиков автокорреляции\n",
    "def plot_autocorrelation(data):\n",
    "    \"\"\"\n",
    "    Строит графики автокорреляции для всех столбцов в DataFrame.\n",
    "    :param data: DataFrame с временными рядами\n",
    "    \"\"\"\n",
    "    # Определение количества строк и столбцов для подграфиков\n",
    "    num_assets = len(data.columns)\n",
    "    num_cols = 3  # Количество столбцов в сетке\n",
    "    num_rows = (num_assets + num_cols - 1) // num_cols  # Количество строк\n",
    "    \n",
    "    # Создание фигуры с подграфиками\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 6 * num_rows))\n",
    "    axes = axes.flatten()  # Преобразование массива в одномерный для удобства\n",
    "    \n",
    "    # Построение графиков автокорреляции\n",
    "    for i, asset in enumerate(data.columns):\n",
    "        pd.plotting.autocorrelation_plot(data[asset].dropna(), ax=axes[i])  # Удаляем NaN перед построением\n",
    "        axes[i].set_title(asset, fontsize=14, fontweight=\"bold\")  # Заголовок графика\n",
    "        axes[i].set_xlabel(\"Lag\", fontsize=12)  # Подпись оси X\n",
    "        axes[i].set_ylabel(\"Autocorrelation\", fontsize=12)  # Подпись оси Y\n",
    "        axes[i].grid(True, linestyle=\"--\", alpha=0.7)  # Сетка\n",
    "    \n",
    "    # Удаление пустых подграфиков\n",
    "    for j in range(num_assets, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "    \n",
    "    # Настройка общего заголовка\n",
    "    fig.suptitle(\"Autocorrelation Plots for All Assets\", fontsize=18, fontweight=\"bold\", y=1.02)\n",
    "    \n",
    "    # Отображение графиков\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Определяем начальную дату\n",
    "start_date = \"2023-01-01\"\n",
    "\n",
    "# Агрегация данных: усреднение по неделям\n",
    "weekly_data = combined_data[selected_portfolio].resample('W').mean()\n",
    "\n",
    "# Фильтрация данных, начиная с start_date\n",
    "filtered_data = weekly_data.loc[start_date:]\n",
    "\n",
    "# Вызов функции для данных\n",
    "plot_autocorrelation(filtered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
