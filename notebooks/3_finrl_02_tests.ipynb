{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8559f2f-8f78-4bfa-be16-102c452fc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22df7d42-30ec-41dd-a37b-4457547aa30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найденные файлы: ['../data\\\\APTUSDT_hourly_data.csv', '../data\\\\BNBUSDT_hourly_data.csv', '../data\\\\BTCUSDT_hourly_data.csv', '../data\\\\CAKEUSDT_hourly_data.csv', '../data\\\\data_compare_eda.csv', '../data\\\\ETHUSDT_hourly_data.csv', '../data\\\\HBARUSDT_hourly_data.csv', '../data\\\\JUPUSDT_hourly_data.csv', '../data\\\\LDOUSDT_hourly_data.csv', '../data\\\\LTCUSDT_hourly_data.csv', '../data\\\\PEPEUSDT_hourly_data.csv', '../data\\\\SOLUSDT_hourly_data.csv', '../data\\\\STRKUSDT_hourly_data.csv', '../data\\\\TONUSDT_hourly_data.csv', '../data\\\\USDCUSDT_hourly_data.csv', '../data\\\\XRPUSDT_hourly_data.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# Шаблон для поиска файлов в папке data\n",
    "file_pattern = os.path.join(data_dir, \"*.csv\")  # Ищем все CSV файлы в папке data\n",
    "\n",
    "# Поиск файлов\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "# Вывод найденных файлов\n",
    "print(\"Найденные файлы:\", file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a4d7f7-c8e4-4400-8de5-79860afd4dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В файле ../data\\data_compare_eda.csv отсутствуют необходимые столбцы.\n",
      "Доступные столбцы: Index(['close time', 'bnbusdt', 'btcusdt', 'cakeusdt', 'ethusdt', 'ltcusdt',\n",
      "       'solusdt', 'strkusdt', 'tonusdt', 'usdcusdt', 'xrpusdt', 'pepeusdt',\n",
      "       'hbarusdt', 'aptusdt', 'ldousdt', 'jupusdt', 'tic'],\n",
      "      dtype='object')\n",
      "                 date    open      high     low   close       volume      tic\n",
      "0 2022-10-19 01:00:00  1.0000  100.0000  1.0000  8.4946  14808472.50  APTUSDT\n",
      "1 2022-10-19 02:00:00  8.5077    8.5895  6.9170  7.4817   6936252.07  APTUSDT\n",
      "2 2022-10-19 03:00:00  7.4817    7.6000  6.6000  6.8147   3917949.82  APTUSDT\n",
      "3 2022-10-19 04:00:00  6.8038    7.5300  6.7456  7.1741   3598717.51  APTUSDT\n",
      "4 2022-10-19 05:00:00  7.1806    8.2500  7.1770  7.9068   5028746.51  APTUSDT\n",
      "Размер итогового DataFrame: (422955, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# Создаем пустой список для хранения данных\n",
    "data_frames = []\n",
    "\n",
    "# Поиск всех CSV-файлов в папке data\n",
    "file_pattern = os.path.join(data_dir, \"*.csv\")  # Шаблон для поиска файлов\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "# Обрабатываем каждый файл\n",
    "for file_path in file_paths:\n",
    "    # Определяем тикер из имени файла (без расширения)\n",
    "    file_name = os.path.basename(file_path)  # Имя файла без пути\n",
    "    symbol = file_name.split(\"_\")[0]  # Берем часть до первого \"_\"\n",
    "\n",
    "    try:\n",
    "        # Читаем CSV-файл\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Очищаем имена столбцов (убираем пробелы и приводим к нижнему регистру)\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "        # Переименовываем столбцы\n",
    "        df.rename(columns={\n",
    "            \"open time\": \"date\",\n",
    "            \"open\": \"open\",\n",
    "            \"high\": \"high\",\n",
    "            \"low\": \"low\",\n",
    "            \"close\": \"close\",\n",
    "            \"volume\": \"volume\"\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Добавляем столбец tic\n",
    "        df[\"tic\"] = symbol\n",
    "\n",
    "        # Проверяем наличие необходимых столбцов\n",
    "        required_columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            df = df[required_columns + [\"tic\"]]\n",
    "        else:\n",
    "            print(f\"В файле {file_path} отсутствуют необходимые столбцы.\")\n",
    "            print(\"Доступные столбцы:\", df.columns)\n",
    "            continue\n",
    "\n",
    "        # Добавляем DataFrame в список\n",
    "        data_frames.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке файла {file_path}: {e}\")\n",
    "\n",
    "# Объединяем все DataFrame в один\n",
    "if data_frames:  # Проверяем, что список не пустой\n",
    "    final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Преобразуем столбец date в формат datetime\n",
    "    final_df[\"date\"] = pd.to_datetime(final_df[\"date\"])\n",
    "\n",
    "    # Выводим первые строки итогового DataFrame\n",
    "    print(final_df.head())\n",
    "    print(\"Размер итогового DataFrame:\", final_df.shape)\n",
    "else:\n",
    "    print(\"Нет данных для объединения.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e109ad-1196-4c8a-8cc1-e419c66c1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['APTUSDT', 'BNBUSDT', 'BTCUSDT', 'CAKEUSDT', 'ETHUSDT', 'HBARUSDT',\n",
       "       'JUPUSDT', 'LDOUSDT', 'LTCUSDT', 'PEPEUSDT', 'SOLUSDT', 'STRKUSDT',\n",
       "       'TONUSDT', 'USDCUSDT', 'XRPUSDT'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf8dcd3-d229-423c-81e4-d4e686ba4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['JUPUSDT', 'PEPEUSDT', 'APTUSDT', 'CAKEUSDT', 'HBARUSDT', 'STRKUSDT', 'USDCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ac6b4b-ba29-4423-8512-c183a5d9d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned start date: 2024-02-20 13:00:00\n",
      "tic\n",
      "APTUSDT    2024-02-20 13:00:00\n",
      "CAKEUSDT   2024-02-20 13:00:00\n",
      "HBARUSDT   2024-02-20 13:00:00\n",
      "JUPUSDT    2024-02-20 13:00:00\n",
      "PEPEUSDT   2024-02-20 13:00:00\n",
      "STRKUSDT   2024-02-20 13:00:00\n",
      "USDCUSDT   2024-02-20 13:00:00\n",
      "Name: date, dtype: datetime64[ns]\n",
      "(70021, 7)\n"
     ]
    }
   ],
   "source": [
    "df_prep = final_df[final_df['tic'].isin(symbols)]\n",
    "\n",
    "max_start_date = df_prep.groupby('tic')['date'].min().max()\n",
    "\n",
    "df_prep_aligned = df_prep[df_prep['date'] >= max_start_date]\n",
    "\n",
    "print(\"Aligned start date:\", max_start_date)\n",
    "print(df_prep_aligned.groupby('tic')['date'].min())  # Должны быть одинаковые даты для всех тикеров\n",
    "print(df_prep_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b928dc-ddea-4609-bf28-495b22e65df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11747</th>\n",
       "      <td>2024-02-20 13:00:00</td>\n",
       "      <td>9.7611</td>\n",
       "      <td>9.9990</td>\n",
       "      <td>9.7409</td>\n",
       "      <td>9.9920</td>\n",
       "      <td>354607.62</td>\n",
       "      <td>APTUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11748</th>\n",
       "      <td>2024-02-20 14:00:00</td>\n",
       "      <td>9.9905</td>\n",
       "      <td>10.0277</td>\n",
       "      <td>9.5872</td>\n",
       "      <td>9.6784</td>\n",
       "      <td>550845.81</td>\n",
       "      <td>APTUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11749</th>\n",
       "      <td>2024-02-20 15:00:00</td>\n",
       "      <td>9.6815</td>\n",
       "      <td>9.6990</td>\n",
       "      <td>9.0609</td>\n",
       "      <td>9.4612</td>\n",
       "      <td>915566.12</td>\n",
       "      <td>APTUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11750</th>\n",
       "      <td>2024-02-20 16:00:00</td>\n",
       "      <td>9.4600</td>\n",
       "      <td>9.5253</td>\n",
       "      <td>9.2789</td>\n",
       "      <td>9.2950</td>\n",
       "      <td>391945.24</td>\n",
       "      <td>APTUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>2024-02-20 17:00:00</td>\n",
       "      <td>9.2952</td>\n",
       "      <td>9.3905</td>\n",
       "      <td>9.1959</td>\n",
       "      <td>9.3817</td>\n",
       "      <td>324567.49</td>\n",
       "      <td>APTUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385468</th>\n",
       "      <td>2025-04-12 03:00:00</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>7286203.00</td>\n",
       "      <td>USDCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385469</th>\n",
       "      <td>2025-04-12 04:00:00</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>12071656.00</td>\n",
       "      <td>USDCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385470</th>\n",
       "      <td>2025-04-12 05:00:00</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>12664778.00</td>\n",
       "      <td>USDCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385471</th>\n",
       "      <td>2025-04-12 06:00:00</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>6987994.00</td>\n",
       "      <td>USDCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385472</th>\n",
       "      <td>2025-04-12 07:00:00</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>1.0004</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>6831370.00</td>\n",
       "      <td>USDCUSDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70021 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    open     high     low   close       volume  \\\n",
       "11747  2024-02-20 13:00:00  9.7611   9.9990  9.7409  9.9920    354607.62   \n",
       "11748  2024-02-20 14:00:00  9.9905  10.0277  9.5872  9.6784    550845.81   \n",
       "11749  2024-02-20 15:00:00  9.6815   9.6990  9.0609  9.4612    915566.12   \n",
       "11750  2024-02-20 16:00:00  9.4600   9.5253  9.2789  9.2950    391945.24   \n",
       "11751  2024-02-20 17:00:00  9.2952   9.3905  9.1959  9.3817    324567.49   \n",
       "...                    ...     ...      ...     ...     ...          ...   \n",
       "385468 2025-04-12 03:00:00  1.0004   1.0005  1.0004  1.0005   7286203.00   \n",
       "385469 2025-04-12 04:00:00  1.0004   1.0005  1.0004  1.0004  12071656.00   \n",
       "385470 2025-04-12 05:00:00  1.0004   1.0005  1.0004  1.0005  12664778.00   \n",
       "385471 2025-04-12 06:00:00  1.0005   1.0005  1.0004  1.0004   6987994.00   \n",
       "385472 2025-04-12 07:00:00  1.0004   1.0005  1.0004  1.0005   6831370.00   \n",
       "\n",
       "             tic  \n",
       "11747    APTUSDT  \n",
       "11748    APTUSDT  \n",
       "11749    APTUSDT  \n",
       "11750    APTUSDT  \n",
       "11751    APTUSDT  \n",
       "...          ...  \n",
       "385468  USDCUSDT  \n",
       "385469  USDCUSDT  \n",
       "385470  USDCUSDT  \n",
       "385471  USDCUSDT  \n",
       "385472  USDCUSDT  \n",
       "\n",
       "[70021 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c7ae8-ed49-47b7-8543-e271c7ed14b9",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf77686-23ec-4e02-9c90-e932a92715fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "(70021, 15)\n",
      "['APTUSDT' 'CAKEUSDT' 'HBARUSDT' 'JUPUSDT' 'PEPEUSDT' 'STRKUSDT'\n",
      " 'USDCUSDT']\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "df = fe.preprocess_data(df_prep_aligned)\n",
    "print(df.shape)\n",
    "print(df['tic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4931dc-a6db-4162-b3da-61afeff8d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69853, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>9.278200</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>9.146400</td>\n",
       "      <td>9.203700</td>\n",
       "      <td>1.585345e+05</td>\n",
       "      <td>APTUSDT</td>\n",
       "      <td>-7.022629e-02</td>\n",
       "      <td>9.732820</td>\n",
       "      <td>9.031410</td>\n",
       "      <td>34.025715</td>\n",
       "      <td>-83.217169</td>\n",
       "      <td>33.638067</td>\n",
       "      <td>9.418024</td>\n",
       "      <td>9.418024</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.686000</td>\n",
       "      <td>2.703000</td>\n",
       "      <td>3.406541e+05</td>\n",
       "      <td>CAKEUSDT</td>\n",
       "      <td>-6.024541e-03</td>\n",
       "      <td>2.759174</td>\n",
       "      <td>2.665226</td>\n",
       "      <td>41.143231</td>\n",
       "      <td>-33.856148</td>\n",
       "      <td>21.313880</td>\n",
       "      <td>2.716360</td>\n",
       "      <td>2.716360</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>2.645657e+07</td>\n",
       "      <td>HBARUSDT</td>\n",
       "      <td>-4.220541e-04</td>\n",
       "      <td>0.110852</td>\n",
       "      <td>0.102728</td>\n",
       "      <td>42.175810</td>\n",
       "      <td>-98.444406</td>\n",
       "      <td>11.643539</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>2.522664e+06</td>\n",
       "      <td>JUPUSDT</td>\n",
       "      <td>-5.419569e-03</td>\n",
       "      <td>0.511789</td>\n",
       "      <td>0.467001</td>\n",
       "      <td>26.238042</td>\n",
       "      <td>-160.682890</td>\n",
       "      <td>73.680138</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.881588e+11</td>\n",
       "      <td>PEPEUSDT</td>\n",
       "      <td>-9.184102e-09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>36.266180</td>\n",
       "      <td>-92.337376</td>\n",
       "      <td>46.857389</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date      open      high       low     close        volume  \\\n",
       "0 2024-02-21 13:00:00  9.278200  9.300000  9.146400  9.203700  1.585345e+05   \n",
       "1 2024-02-21 13:00:00  2.720000  2.720000  2.686000  2.703000  3.406541e+05   \n",
       "2 2024-02-21 13:00:00  0.104200  0.105100  0.102300  0.103900  2.645657e+07   \n",
       "3 2024-02-21 13:00:00  0.473300  0.475600  0.465100  0.470300  2.522664e+06   \n",
       "4 2024-02-21 13:00:00  0.000001  0.000001  0.000001  0.000001  1.881588e+11   \n",
       "\n",
       "        tic          macd   boll_ub   boll_lb     rsi_30      cci_30  \\\n",
       "0   APTUSDT -7.022629e-02  9.732820  9.031410  34.025715  -83.217169   \n",
       "1  CAKEUSDT -6.024541e-03  2.759174  2.665226  41.143231  -33.856148   \n",
       "2  HBARUSDT -4.220541e-04  0.110852  0.102728  42.175810  -98.444406   \n",
       "3   JUPUSDT -5.419569e-03  0.511789  0.467001  26.238042 -160.682890   \n",
       "4  PEPEUSDT -9.184102e-09  0.000001  0.000001  36.266180  -92.337376   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  \\\n",
       "0  33.638067      9.418024      9.418024   \n",
       "1  21.313880      2.716360      2.716360   \n",
       "2  11.643539      0.106384      0.106384   \n",
       "3  73.680138      0.491876      0.491876   \n",
       "4  46.857389      0.000001      0.000001   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "1  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "2  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "3  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "4  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "1  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "2  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "3  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "4  tic                   APTUSDT  CAKEUSDT  HBARU...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add covariance matrix as states\n",
    "# add covariance matrix as states\n",
    "df = df.sort_values(['date','tic'], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back\n",
    "lb_val = 24\n",
    "lookback = lb_val\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback = data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  return_list.append(return_lookback)\n",
    "\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fdfa0b-e122-4dbe-be54-f6cbab43182f",
   "metadata": {},
   "source": [
    "## Design Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec8cd0d6-9853-4c28-978b-4b45f4429874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training period: 2024-02-21 13:00:00\n",
      "End of training period: 2025-01-19 04:00:00\n"
     ]
    }
   ],
   "source": [
    "# Определяем границы для обучающей выборки\n",
    "start_train = df['date'].min()  # Самая ранняя дата в данных\n",
    "end_train = df['date'].quantile(0.8)  # 80% данных для обучения (по времени)\n",
    "\n",
    "print(\"Start of training period:\", start_train)\n",
    "print(\"End of training period:\", end_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49593cd6-aa24-41f5-87c8-fe3df65caa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of testing period: 2025-01-19 04:00:00\n",
      "End of testing period: 2025-04-12 07:00:00\n"
     ]
    }
   ],
   "source": [
    "# Определяем границы для тестовой выборки\n",
    "start_test = end_train  # Начало тестовой выборки = конец обучающей\n",
    "end_test = df['date'].max()  # Самая поздняя дата в данных\n",
    "\n",
    "print(\"Start of testing period:\", start_test)\n",
    "print(\"End of testing period:\", end_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f415100-8f87-474a-a73a-ee2ab5277f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>9.278200</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>9.146400</td>\n",
       "      <td>9.203700</td>\n",
       "      <td>1.585345e+05</td>\n",
       "      <td>APTUSDT</td>\n",
       "      <td>-7.022629e-02</td>\n",
       "      <td>9.732820</td>\n",
       "      <td>9.031410</td>\n",
       "      <td>34.025715</td>\n",
       "      <td>-83.217169</td>\n",
       "      <td>33.638067</td>\n",
       "      <td>9.418024</td>\n",
       "      <td>9.418024</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.686000</td>\n",
       "      <td>2.703000</td>\n",
       "      <td>3.406541e+05</td>\n",
       "      <td>CAKEUSDT</td>\n",
       "      <td>-6.024541e-03</td>\n",
       "      <td>2.759174</td>\n",
       "      <td>2.665226</td>\n",
       "      <td>41.143231</td>\n",
       "      <td>-33.856148</td>\n",
       "      <td>21.313880</td>\n",
       "      <td>2.716360</td>\n",
       "      <td>2.716360</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>2.645657e+07</td>\n",
       "      <td>HBARUSDT</td>\n",
       "      <td>-4.220541e-04</td>\n",
       "      <td>0.110852</td>\n",
       "      <td>0.102728</td>\n",
       "      <td>42.175810</td>\n",
       "      <td>-98.444406</td>\n",
       "      <td>11.643539</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>2.522664e+06</td>\n",
       "      <td>JUPUSDT</td>\n",
       "      <td>-5.419569e-03</td>\n",
       "      <td>0.511789</td>\n",
       "      <td>0.467001</td>\n",
       "      <td>26.238042</td>\n",
       "      <td>-160.682890</td>\n",
       "      <td>73.680138</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-21 13:00:00</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.881588e+11</td>\n",
       "      <td>PEPEUSDT</td>\n",
       "      <td>-9.184102e-09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>36.266180</td>\n",
       "      <td>-92.337376</td>\n",
       "      <td>46.857389</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>[[0.00013639724644876403, 0.000106712407983733...</td>\n",
       "      <td>tic                   APTUSDT  CAKEUSDT  HBARU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date      open      high       low     close        volume  \\\n",
       "0 2024-02-21 13:00:00  9.278200  9.300000  9.146400  9.203700  1.585345e+05   \n",
       "0 2024-02-21 13:00:00  2.720000  2.720000  2.686000  2.703000  3.406541e+05   \n",
       "0 2024-02-21 13:00:00  0.104200  0.105100  0.102300  0.103900  2.645657e+07   \n",
       "0 2024-02-21 13:00:00  0.473300  0.475600  0.465100  0.470300  2.522664e+06   \n",
       "0 2024-02-21 13:00:00  0.000001  0.000001  0.000001  0.000001  1.881588e+11   \n",
       "\n",
       "        tic          macd   boll_ub   boll_lb     rsi_30      cci_30  \\\n",
       "0   APTUSDT -7.022629e-02  9.732820  9.031410  34.025715  -83.217169   \n",
       "0  CAKEUSDT -6.024541e-03  2.759174  2.665226  41.143231  -33.856148   \n",
       "0  HBARUSDT -4.220541e-04  0.110852  0.102728  42.175810  -98.444406   \n",
       "0   JUPUSDT -5.419569e-03  0.511789  0.467001  26.238042 -160.682890   \n",
       "0  PEPEUSDT -9.184102e-09  0.000001  0.000001  36.266180  -92.337376   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  \\\n",
       "0  33.638067      9.418024      9.418024   \n",
       "0  21.313880      2.716360      2.716360   \n",
       "0  11.643539      0.106384      0.106384   \n",
       "0  73.680138      0.491876      0.491876   \n",
       "0  46.857389      0.000001      0.000001   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "0  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "0  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "0  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "0  [[0.00013639724644876403, 0.000106712407983733...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "0  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "0  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "0  tic                   APTUSDT  CAKEUSDT  HBARU...  \n",
       "0  tic                   APTUSDT  CAKEUSDT  HBARU...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_split(df, start_train, end_train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f1ee8-4b94-4d4d-a165-27720b82846a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/learnmore1/deep-reinforcement-learning-for-stock-trading-1#Part-5.-Design-Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4bd528b-38d3-47ba-9052-2897546b928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DDPG\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"A single stock trading environment for OpenAI gym\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            input data\n",
    "        stock_dim : int\n",
    "            number of unique stocks\n",
    "        hmax : int\n",
    "            maximum number of shares to trade\n",
    "        initial_amount : int\n",
    "            start money\n",
    "        transaction_cost_pct: float\n",
    "            transaction cost percentage per trade\n",
    "        reward_scaling: float\n",
    "            scaling factor for reward, good for training\n",
    "        state_space: int\n",
    "            the dimension of input features\n",
    "        action_space: int\n",
    "            equals stock dimension\n",
    "        tech_indicator_list: list\n",
    "            a list of technical indicator names\n",
    "        turbulence_threshold: int\n",
    "            a threshold to control risk aversion\n",
    "        day: int\n",
    "            an increment number to control date\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _sell_stock()\n",
    "        perform sell action based on the sign of the action\n",
    "    _buy_stock()\n",
    "        perform buy action based on the sign of the action\n",
    "    step()\n",
    "        at each step the agent will return actions, then \n",
    "        we will calculate the reward, and return the next observation.\n",
    "    reset()\n",
    "        reset the environment\n",
    "    render()\n",
    "        use render to return other functions\n",
    "    save_asset_memory()\n",
    "        return account value at each time step\n",
    "    save_action_memory()\n",
    "        return actions/positions at each time step\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, \n",
    "                df,\n",
    "                stock_dim,\n",
    "                hmax,\n",
    "                initial_amount,\n",
    "                transaction_cost_pct,\n",
    "                reward_scaling,\n",
    "                state_space,\n",
    "                action_space,\n",
    "                tech_indicator_list,\n",
    "                turbulence_threshold=None,\n",
    "                lookback=24 * 30 * 3,\n",
    "                day = 0):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.lookback=lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct =transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        # self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
    "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
    "        # self.action_space = spaces.Box(low=0, high=1, shape=(self.stock_dim,), dtype=np.float32)\n",
    "        # Shape = (34, 30)\n",
    "        # covariance matrix + technical indicators\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.terminal = False     \n",
    "        self.turbulence_threshold = turbulence_threshold        \n",
    "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # Check if the episode is done\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "    \n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            plt.plot(df.daily_return.cumsum(), 'r')\n",
    "            plt.savefig('results/cumulative_reward.png')\n",
    "            plt.close()\n",
    "    \n",
    "            plt.plot(self.portfolio_return_memory, 'r')\n",
    "            plt.savefig('results/rewards.png')\n",
    "            plt.close()\n",
    "    \n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "    \n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() != 0:\n",
    "                sharpe = ((24 * 30 * 3)**0.5) * df_daily_return['daily_return'].mean() / \\\n",
    "                         df_daily_return['daily_return'].std()\n",
    "                print(\"Sharpe: \", sharpe)\n",
    "            print(\"=================================\")\n",
    "    \n",
    "            # Return observation, reward, terminated, truncated, and info\n",
    "            return self.state, self.reward, self.terminal, False, {}\n",
    "    \n",
    "        else:\n",
    "            # Normalize actions\n",
    "            weights = self.softmax_normalization(actions)\n",
    "            self.actions_memory.append(weights)\n",
    "            last_day_memory = self.data\n",
    "    \n",
    "            # Load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state = np.append(\n",
    "                np.array(self.covs),\n",
    "                [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "                axis=0\n",
    "            )\n",
    "    \n",
    "            # Calculate portfolio return\n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values) - 1) * weights)\n",
    "            new_portfolio_value = self.portfolio_value * (1 + portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "    \n",
    "            # Save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "    \n",
    "            # Reward is the new portfolio value\n",
    "            self.reward = new_portfolio_value\n",
    "    \n",
    "            # Return observation, reward, terminated, truncated, and info\n",
    "            return self.state, self.reward, self.terminal, False, {}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Если нужно, инициализируйте генератор случайных чисел\n",
    "        if seed is not None:\n",
    "            self._seed(seed)\n",
    "        \n",
    "        # Остальная логика вашего метода reset()\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state = np.append(\n",
    "            np.array(self.covs),\n",
    "            [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "            axis=0\n",
    "        )\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.terminal = False\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [[1 / self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory = [self.data.date.unique()[0]]\n",
    "        return self.state, {}  # Возвращайте состояние и пустой словарь (info)\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "        \n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator/denominator\n",
    "        return softmax_output\n",
    "\n",
    "    \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        #print(len(date_list))\n",
    "        #print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "        \n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d7300aa-372b-46f0-b103-7f604b8e6a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 7, State Space: 7\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f9f6a8d-4312-405a-ae58-b7780cf54a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "# Create Folders\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96f1d202-91c0-4370-a8e8-bc8e249d4c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596d7a7-993b-4c30-bc42-553037e042bb",
   "metadata": {},
   "source": [
    "## Implement DRL Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebee8b4",
   "metadata": {},
   "source": [
    "## Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a85d9984-02a4-4b7d-a5fc-a91b79448760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222f96b-c7ac-4835-89e8-bda73cd305bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)\n",
    "\n",
    "trained_a2c.save('./trained_models/trained_a2c.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee251f32-bc06-474d-8986-853f54cfdddb",
   "metadata": {},
   "source": [
    "## Model 2: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bd1e3-9ba3-487e-832c-74f6cb23fd18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=80000)\n",
    "\n",
    "trained_ppo.save('./trained_models/trained_ppo.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473de05e-0a65-4b4c-b758-1776ab10c736",
   "metadata": {},
   "source": [
    "## Model 3: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60369ec-4bd3-4d52-b46d-77bc43074da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)\n",
    "\n",
    "trained_ddpg.save('./trained_models/trained_ddpg.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30597b1",
   "metadata": {},
   "source": [
    "## Model 3: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC \n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "\n",
    "# Параметры, специфичные для ПОЛИТИКИ (архитектура сети)\n",
    "POLICY_KWARGS = dict(net_arch=[256, 256])\n",
    "\n",
    "# ОСНОВНЫЕ параметры модели SAC (все остальное)\n",
    "MODEL_KWARGS = {\n",
    "    \"buffer_size\": 100000,\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"gamma\": 0.99,\n",
    "    \"tau\": 0.005,\n",
    "    \"ent_coef\": 'auto',\n",
    "    \"learning_starts\": 10000\n",
    "    # policy_kwargs УБРАН ОТСЮДА\n",
    "}\n",
    "\n",
    "\n",
    "model_sac = agent.get_model(\n",
    "    \"sac\",\n",
    "    policy_kwargs=POLICY_KWARGS, \n",
    "    model_kwargs=MODEL_KWARGS   \n",
    ")\n",
    "\n",
    "\n",
    "trained_sac = agent.train_model(\n",
    "    model=model_sac,\n",
    "    tb_log_name='sac',\n",
    "    total_timesteps=100000\n",
    ")\n",
    "\n",
    "\n",
    "trained_sac.save('./trained_models/trained_sac.zip')\n",
    "\n",
    "print(\"Модель SAC успешно создана, обучена и сохранена.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a126d-3096-42f3-af3c-c5832b465e3f",
   "metadata": {},
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c30492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Musonda2day/Asset-Portfolio-Management-usingDeep-Reinforcement-Learning-/blob/main/8.%20DRL_Portfolios.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f052024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rathiromil13/DS-5500-Project-Portfolio-Optimization-Using-Deep-Reinforcement-Learning/blob/master/documents/Final_Report_Portfolio_Optimization_using_Deep_Reinforcement_Learning.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82b3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Конфигурация\n",
    "DATA_DIR = \"../data\"\n",
    "MODELS_PREDICTION_DIR = os.path.join(DATA_DIR, \"models_predictions\")\n",
    "\n",
    "# Создание папки для сохранения результатов\n",
    "os.makedirs(MODELS_PREDICTION_DIR, exist_ok=True)\n",
    "\n",
    "def evaluate_and_save_models(models, df, env_kwargs):\n",
    "    \"\"\"\n",
    "    Оценивает модели и сохраняет результаты в CSV файлы.\n",
    "\n",
    "    Параметры:\n",
    "        models (dict): Словарь с моделями, где ключ - название модели, значение - объект модели.\n",
    "        df (pd.DataFrame): Исходный DataFrame с данными.\n",
    "        env_kwargs (dict): Параметры для создания среды StockPortfolioEnv.\n",
    "\n",
    "    Возвращает:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Разделение данных на тестовый период\n",
    "    trade_data = data_split(df, start_test, end_test)\n",
    "    print(f\"Тестовые данные: {trade_data.shape}\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Обработка модели: {model_name}\")\n",
    "        try:\n",
    "            # Создание среды для торговли\n",
    "            trade_env = StockPortfolioEnv(df=trade_data, **env_kwargs)\n",
    "\n",
    "            # Получение предсказаний модели\n",
    "            df_daily_return, df_actions = DRLAgent.DRL_prediction(\n",
    "                model=model,\n",
    "                environment=trade_env\n",
    "            )\n",
    "\n",
    "            # Убедимся, что столбец 'date' имеет формат datetime\n",
    "            if 'date' in df_daily_return.columns:\n",
    "                df_daily_return['date'] = pd.to_datetime(df_daily_return['date'])\n",
    "\n",
    "            # Сохранение результатов\n",
    "            save_model_predictions(\n",
    "                df_daily_return=df_daily_return,\n",
    "                df_actions=df_actions,\n",
    "                model_name=model_name,\n",
    "                data_dir=DATA_DIR\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке модели {model_name}: {e}\")\n",
    "\n",
    "def save_model_predictions(df_daily_return, df_actions, model_name, data_dir):\n",
    "    \"\"\"\n",
    "    Сохраняет результаты предсказаний модели (доходность и действия) в CSV файлы.\n",
    "\n",
    "    Параметры:\n",
    "        df_daily_return (pd.DataFrame): DataFrame с ежедневной доходностью.\n",
    "        df_actions (pd.DataFrame): DataFrame с действиями модели.\n",
    "        model_name (str): Название модели (используется в имени файла).\n",
    "        data_dir (str): Путь к папке data.\n",
    "\n",
    "    Возвращает:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Путь к папке для сохранения файлов\n",
    "    models_prediction_dir = os.path.join(data_dir, \"models_predictions\")\n",
    "\n",
    "    # Имена файлов\n",
    "    return_file_name = os.path.join(models_prediction_dir, f\"{model_name}_return_series.csv\")\n",
    "    actions_file_name = os.path.join(models_prediction_dir, f\"{model_name}_actions.csv\")\n",
    "\n",
    "    try:\n",
    "        # Сохранение DataFrame с ежедневной доходностью\n",
    "        df_daily_return.to_csv(return_file_name, index=False)\n",
    "        print(f\"Файл '{return_file_name}' успешно сохранен.\")\n",
    "\n",
    "        # Сохранение DataFrame с действиями модели\n",
    "        df_actions.to_csv(actions_file_name, index=True)\n",
    "        print(f\"Файл '{actions_file_name}' успешно сохранен.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении файлов для модели {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4876a203",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_a2c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_a2c\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmodel_a2c\u001b[49m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_ppo\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_ppo,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_ddpg\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_ddpg,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_sac\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_sac\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Вызов функции для оценки и сохранения результатов моделей\u001b[39;00m\n\u001b[0;32m     10\u001b[0m evaluate_and_save_models(models\u001b[38;5;241m=\u001b[39mmodels, df\u001b[38;5;241m=\u001b[39mdf, env_kwargs\u001b[38;5;241m=\u001b[39menv_kwargs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_a2c' is not defined"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"model_a2c\": model_a2c,\n",
    "    \"model_ppo\": model_ppo,\n",
    "    \"model_ddpg\": model_ddpg,\n",
    "    \"model_sac\": model_sac\n",
    "}\n",
    "\n",
    "\n",
    "# Вызов функции для оценки и сохранения результатов моделей\n",
    "evaluate_and_save_models(models=models, df=df, env_kwargs=env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78905051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка модели из: ./trained_models/trained_sac.zip\n",
      "Модель SAC успешно загружена: <class 'stable_baselines3.sac.sac.SAC'>\n",
      "\n",
      "Начало оценки загруженной модели...\n",
      "Тестовые данные: (13965, 17)\n",
      "Обработка модели: SAC_Trained\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:503923.67905657337\n",
      "Sharpe:  -1.1745186732288562\n",
      "=================================\n",
      "hit end!\n",
      "Файл '../data\\models_predictions\\SAC_Trained_return_series.csv' успешно сохранен.\n",
      "Файл '../data\\models_predictions\\SAC_Trained_actions.csv' успешно сохранен.\n",
      "\n",
      "Оценка завершена. Результаты должны быть сохранены в: ../data\\models_predictions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from stable_baselines3 import SAC\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv # Не строго обязателен для load, но может быть нужен DRLAgent\n",
    "\n",
    "# --- ШАГ 0: Убедитесь, что ВСЕ эти компоненты определены/импортированы ВЫШЕ ---\n",
    "\n",
    "# 0.1. Ваш класс среды\n",
    "# from your_module import StockPortfolioEnv\n",
    "# class StockPortfolioEnv(gym.Env): ... (полное определение класса)\n",
    "\n",
    "# 0.2. Функция разделения данных\n",
    "# from your_module import data_split\n",
    "# def data_split(df, start, end):\n",
    "#     \"\"\"\n",
    "#     ВАЖНО: Убедитесь, что эта функция возвращает DataFrame trade_data\n",
    "#     с индексом, который ожидает StockPortfolioEnv (вероятно, сброшенный\n",
    "#     индекс 0, 1, 2... для дней внутри тестового периода).\n",
    "#     Пример реализации из предыдущего ответа:\n",
    "#     \"\"\"\n",
    "#     print(f\"Разделение данных с {start} по {end}\")\n",
    "#     # Убедимся, что индекс df содержит дату (может быть MultiIndex)\n",
    "#     if isinstance(df.index, pd.MultiIndex):\n",
    "#         data = df[(df.index.get_level_values('date') >= start) & (df.index.get_level_values('date') < end)].copy()\n",
    "#     else: # Если индекс - просто дата\n",
    "#         data = df[(df.index >= start) & (df.index < end)].copy()\n",
    "#\n",
    "#     if data.empty:\n",
    "#         raise ValueError(f\"Нет данных для тестового периода {start} - {end}\")\n",
    "#\n",
    "#     # Сбросим существующий индекс (date, tic или просто date)\n",
    "#     data = data.reset_index()\n",
    "#\n",
    "#     # Переиндексируем дни 0, 1, 2... для среды StockPortfolioEnv\n",
    "#     unique_dates = data['date'].unique()\n",
    "#     date_to_day_map = {date: i for i, date in enumerate(unique_dates)}\n",
    "#     data['day_index'] = data['date'].map(date_to_day_map)\n",
    "#\n",
    "#     # Установим новый индекс и отсортируем\n",
    "#     # ВАЖНО: Проверьте, ожидает ли StockPortfolioEnv 'day_index' или просто числовой индекс\n",
    "#     # Если используется df.loc[self.day, :], то 'day_index' как индекс идеален\n",
    "#     data = data.set_index('day_index').sort_index()\n",
    "#     print(f\"Размер тестовых данных после обработки: {data.shape}\")\n",
    "#     print(f\"Уникальных дней в тесте: {len(unique_dates)}\")\n",
    "#     return data\n",
    "\n",
    "# 0.3. Функции оценки и сохранения\n",
    "# def evaluate_and_save_models(models, df, env_kwargs, start_test, end_test, data_split_func): ... (ваш код)\n",
    "# def save_model_predictions(df_daily_return, df_actions, model_name, data_dir): ... (ваш код)\n",
    "\n",
    "# 0.4. Класс DRLAgent (если evaluate_and_save_models его использует)\n",
    "# from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "# 0.5. Переменные\n",
    "# df = pd.read_pickle(\"path/to/your/processed_dataframe.pkl\") # Загрузите ПОЛНЫЙ датафрейм\n",
    "# stock_dimension = df['tic'].nunique() # Определите stock_dimension\n",
    "# state_space = stock_dimension # Определите state_space (убедитесь, что он правильный!)\n",
    "# indicators = ['list', 'of', 'your', 'indicators'] # Определите список индикаторов\n",
    "# DATA_DIR = \"../data\"\n",
    "# MODELS_PREDICTION_DIR = os.path.join(DATA_DIR, \"models_predictions\")\n",
    "# os.makedirs(MODELS_PREDICTION_DIR, exist_ok=True)\n",
    "\n",
    "# # Даты теста\n",
    "# start_test = pd.Timestamp(\"2022-01-01\") # Используйте Timestamp для надежности\n",
    "# end_test = pd.Timestamp(\"2023-01-01\")\n",
    "\n",
    "# # Параметры среды (ДОЛЖНЫ СОВПАДАТЬ с параметрами обучения!)\n",
    "# env_kwargs = {\n",
    "#     \"hmax\": 100,\n",
    "#     \"initial_amount\": 1000000,\n",
    "#     \"transaction_cost_pct\": 0.001,\n",
    "#     \"state_space\": state_space, # Убедитесь, что state_space определен выше\n",
    "#     \"stock_dim\": stock_dimension, # Убедитесь, что stock_dimension определен выше\n",
    "#     \"tech_indicator_list\": indicators, # Убедитесь, что indicators определен выше\n",
    "#     \"action_space\": stock_dimension,\n",
    "#     \"reward_scaling\": 1e-4,\n",
    "#     # \"turbulence_threshold\": None, # Добавьте, если использовали при обучении\n",
    "#     # \"lookback\": ..., # Добавьте, если использовали при обучении\n",
    "# }\n",
    "\n",
    "# Путь к модели\n",
    "model_path = './trained_models/trained_sac.zip'\n",
    "# --- КОНЕЦ БЛОКА НЕОБХОДИМЫХ ОПРЕДЕЛЕНИЙ ---\n",
    "\n",
    "\n",
    "# --- ШАГ 1: Загрузка Модели ---\n",
    "print(f\"Загрузка модели из: {model_path}\")\n",
    "try:\n",
    "    # Загрузка модели. Передача env не обязательна, т.к. SB3 сохраняет структуру.\n",
    "    loaded_model_sac = SAC.load(model_path)\n",
    "    print(f\"Модель SAC успешно загружена: {type(loaded_model_sac)}\")\n",
    "\n",
    "    # --- ШАГ 2: Подготовка к Оценке ---\n",
    "    models_to_evaluate = {\n",
    "        \"SAC_Trained\": loaded_model_sac # Даем модели осмысленное имя для сохранения файлов\n",
    "        # Сюда можно добавить другие модели для сравнения\n",
    "        # \"DDPG_Trained\": SAC.load('./trained_models/trained_ddpg.zip'),\n",
    "    }\n",
    "\n",
    "    # --- ШАГ 3: Запуск Оценки ---\n",
    "    print(\"\\nНачало оценки загруженной модели...\")\n",
    "    # Передаем все необходимые аргументы в вашу функцию\n",
    "    evaluate_and_save_models(\n",
    "        models=models_to_evaluate,\n",
    "        df=df,                     # Полный датафрейм\n",
    "        env_kwargs=env_kwargs,     # Параметры среды (те же, что при обучении)\n",
    "        # Передаем start_test, end_test и data_split в функцию оценки, если они нужны там\n",
    "        # Если evaluate_and_save_models сама вызывает data_split, то:\n",
    "        # start_test=start_test,\n",
    "        # end_test=end_test,\n",
    "        # data_split_func=data_split # Если функция передается как аргумент\n",
    "    )\n",
    "\n",
    "    print(\"\\nОценка завершена. Результаты должны быть сохранены в:\", MODELS_PREDICTION_DIR)\n",
    "\n",
    "# --- ШАГ 4: Обработка Ошибок ---\n",
    "except FileNotFoundError:\n",
    "    print(f\"ОШИБКА: Файл модели не найден по пути {model_path}\")\n",
    "except NameError as e:\n",
    "    print(f\"\\nОШИБКА: Не определена переменная или функция: {e}\")\n",
    "    print(\"--- Пожалуйста, убедитесь, что ВСЕ компоненты из 'ШАГ 0' определены и импортированы ПЕРЕД этим кодом! ---\")\n",
    "    print(\"--- Проверьте наличие: df, start_test, end_test, env_kwargs, StockPortfolioEnv, data_split, evaluate_and_save_models, save_model_predictions, DRLAgent (если используется) ---\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nОШИБКА значения (возможно, в data_split или внутри среды): {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nНеожиданная ОШИБКА при загрузке или оценке модели: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc() # Печатаем полный traceback для диагностики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b4283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
