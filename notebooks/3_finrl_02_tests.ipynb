{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8559f2f-8f78-4bfa-be16-102c452fc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df7d42-30ec-41dd-a37b-4457547aa30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# Шаблон для поиска файлов в папке data\n",
    "file_pattern = os.path.join(data_dir, \"*.csv\")  # Ищем все CSV файлы в папке data\n",
    "\n",
    "# Поиск файлов\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "# Вывод найденных файлов\n",
    "print(\"Найденные файлы:\", file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4d7f7-c8e4-4400-8de5-79860afd4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Путь к папке с данными\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# Создаем пустой список для хранения данных\n",
    "data_frames = []\n",
    "\n",
    "# Поиск всех CSV-файлов в папке data\n",
    "file_pattern = os.path.join(data_dir, \"*.csv\")  # Шаблон для поиска файлов\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "# Обрабатываем каждый файл\n",
    "for file_path in file_paths:\n",
    "    # Определяем тикер из имени файла (без расширения)\n",
    "    file_name = os.path.basename(file_path)  # Имя файла без пути\n",
    "    symbol = file_name.split(\"_\")[0]  # Берем часть до первого \"_\"\n",
    "\n",
    "    try:\n",
    "        # Читаем CSV-файл\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Очищаем имена столбцов (убираем пробелы и приводим к нижнему регистру)\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "        # Переименовываем столбцы\n",
    "        df.rename(columns={\n",
    "            \"open time\": \"date\",\n",
    "            \"open\": \"open\",\n",
    "            \"high\": \"high\",\n",
    "            \"low\": \"low\",\n",
    "            \"close\": \"close\",\n",
    "            \"volume\": \"volume\"\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Добавляем столбец tic\n",
    "        df[\"tic\"] = symbol\n",
    "\n",
    "        # Проверяем наличие необходимых столбцов\n",
    "        required_columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            df = df[required_columns + [\"tic\"]]\n",
    "        else:\n",
    "            print(f\"В файле {file_path} отсутствуют необходимые столбцы.\")\n",
    "            print(\"Доступные столбцы:\", df.columns)\n",
    "            continue\n",
    "\n",
    "        # Добавляем DataFrame в список\n",
    "        data_frames.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке файла {file_path}: {e}\")\n",
    "\n",
    "# Объединяем все DataFrame в один\n",
    "if data_frames:  # Проверяем, что список не пустой\n",
    "    final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Преобразуем столбец date в формат datetime\n",
    "    final_df[\"date\"] = pd.to_datetime(final_df[\"date\"])\n",
    "\n",
    "    # Выводим первые строки итогового DataFrame\n",
    "    print(final_df.head())\n",
    "    print(\"Размер итогового DataFrame:\", final_df.shape)\n",
    "else:\n",
    "    print(\"Нет данных для объединения.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e109ad-1196-4c8a-8cc1-e419c66c1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf8dcd3-d229-423c-81e4-d4e686ba4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['JUPUSDT', 'PEPEUSDT', 'APTUSDT', 'CAKEUSDT', 'HBARUSDT', 'STRKUSDT', 'USDCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac6b4b-ba29-4423-8512-c183a5d9d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = final_df[final_df['tic'].isin(symbols)]\n",
    "\n",
    "max_start_date = df_prep.groupby('tic')['date'].min().max()\n",
    "\n",
    "df_prep_aligned = df_prep[df_prep['date'] >= max_start_date]\n",
    "\n",
    "print(\"Aligned start date:\", max_start_date)\n",
    "print(df_prep_aligned.groupby('tic')['date'].min())  # Должны быть одинаковые даты для всех тикеров\n",
    "print(df_prep_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b928dc-ddea-4609-bf28-495b22e65df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c7ae8-ed49-47b7-8543-e271c7ed14b9",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf77686-23ec-4e02-9c90-e932a92715fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "df = fe.preprocess_data(df_prep_aligned)\n",
    "print(df.shape)\n",
    "print(df['tic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4931dc-a6db-4162-b3da-61afeff8d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add covariance matrix as states\n",
    "# add covariance matrix as states\n",
    "df = df.sort_values(['date','tic'], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back\n",
    "lb_val = 24\n",
    "lookback = lb_val\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback = data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  return_list.append(return_lookback)\n",
    "\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fdfa0b-e122-4dbe-be54-f6cbab43182f",
   "metadata": {},
   "source": [
    "## Design Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8cd0d6-9853-4c28-978b-4b45f4429874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем границы для обучающей выборки\n",
    "start_train = df['date'].min()  # Самая ранняя дата в данных\n",
    "end_train = df['date'].quantile(0.8)  # 80% данных для обучения (по времени)\n",
    "\n",
    "print(\"Start of training period:\", start_train)\n",
    "print(\"End of training period:\", end_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49593cd6-aa24-41f5-87c8-fe3df65caa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем границы для тестовой выборки\n",
    "start_test = end_train  # Начало тестовой выборки = конец обучающей\n",
    "end_test = df['date'].max()  # Самая поздняя дата в данных\n",
    "\n",
    "print(\"Start of testing period:\", start_test)\n",
    "print(\"End of testing period:\", end_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f415100-8f87-474a-a73a-ee2ab5277f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(df, start_train, end_train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f1ee8-4b94-4d4d-a165-27720b82846a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/learnmore1/deep-reinforcement-learning-for-stock-trading-1#Part-5.-Design-Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4bd528b-38d3-47ba-9052-2897546b928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DDPG\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"A single stock trading environment for OpenAI gym\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            input data\n",
    "        stock_dim : int\n",
    "            number of unique stocks\n",
    "        hmax : int\n",
    "            maximum number of shares to trade\n",
    "        initial_amount : int\n",
    "            start money\n",
    "        transaction_cost_pct: float\n",
    "            transaction cost percentage per trade\n",
    "        reward_scaling: float\n",
    "            scaling factor for reward, good for training\n",
    "        state_space: int\n",
    "            the dimension of input features\n",
    "        action_space: int\n",
    "            equals stock dimension\n",
    "        tech_indicator_list: list\n",
    "            a list of technical indicator names\n",
    "        turbulence_threshold: int\n",
    "            a threshold to control risk aversion\n",
    "        day: int\n",
    "            an increment number to control date\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _sell_stock()\n",
    "        perform sell action based on the sign of the action\n",
    "    _buy_stock()\n",
    "        perform buy action based on the sign of the action\n",
    "    step()\n",
    "        at each step the agent will return actions, then \n",
    "        we will calculate the reward, and return the next observation.\n",
    "    reset()\n",
    "        reset the environment\n",
    "    render()\n",
    "        use render to return other functions\n",
    "    save_asset_memory()\n",
    "        return account value at each time step\n",
    "    save_action_memory()\n",
    "        return actions/positions at each time step\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, \n",
    "                df,\n",
    "                stock_dim,\n",
    "                hmax,\n",
    "                initial_amount,\n",
    "                transaction_cost_pct,\n",
    "                reward_scaling,\n",
    "                state_space,\n",
    "                action_space,\n",
    "                tech_indicator_list,\n",
    "                turbulence_threshold=None,\n",
    "                lookback=24 * 30 * 3,\n",
    "                day = 0):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.lookback=lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct =transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        # self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
    "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
    "        # self.action_space = spaces.Box(low=0, high=1, shape=(self.stock_dim,), dtype=np.float32)\n",
    "        # Shape = (34, 30)\n",
    "        # covariance matrix + technical indicators\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.terminal = False     \n",
    "        self.turbulence_threshold = turbulence_threshold        \n",
    "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # Check if the episode is done\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "    \n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            plt.plot(df.daily_return.cumsum(), 'r')\n",
    "            plt.savefig('results/cumulative_reward.png')\n",
    "            plt.close()\n",
    "    \n",
    "            plt.plot(self.portfolio_return_memory, 'r')\n",
    "            plt.savefig('results/rewards.png')\n",
    "            plt.close()\n",
    "    \n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "    \n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() != 0:\n",
    "                sharpe = ((24 * 30 * 3)**0.5) * df_daily_return['daily_return'].mean() / \\\n",
    "                         df_daily_return['daily_return'].std()\n",
    "                print(\"Sharpe: \", sharpe)\n",
    "            print(\"=================================\")\n",
    "    \n",
    "            # Return observation, reward, terminated, truncated, and info\n",
    "            return self.state, self.reward, self.terminal, False, {}\n",
    "    \n",
    "        else:\n",
    "            # Normalize actions\n",
    "            weights = self.softmax_normalization(actions)\n",
    "            self.actions_memory.append(weights)\n",
    "            last_day_memory = self.data\n",
    "    \n",
    "            # Load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state = np.append(\n",
    "                np.array(self.covs),\n",
    "                [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "                axis=0\n",
    "            )\n",
    "    \n",
    "            # Calculate portfolio return\n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values) - 1) * weights)\n",
    "            new_portfolio_value = self.portfolio_value * (1 + portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "    \n",
    "            # Save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "    \n",
    "            # Reward is the new portfolio value\n",
    "            self.reward = new_portfolio_value\n",
    "    \n",
    "            # Return observation, reward, terminated, truncated, and info\n",
    "            return self.state, self.reward, self.terminal, False, {}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Если нужно, инициализируйте генератор случайных чисел\n",
    "        if seed is not None:\n",
    "            self._seed(seed)\n",
    "        \n",
    "        # Остальная логика вашего метода reset()\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state = np.append(\n",
    "            np.array(self.covs),\n",
    "            [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "            axis=0\n",
    "        )\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.terminal = False\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [[1 / self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory = [self.data.date.unique()[0]]\n",
    "        return self.state, {}  # Возвращайте состояние и пустой словарь (info)\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "        \n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator/denominator\n",
    "        return softmax_output\n",
    "\n",
    "    \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        #print(len(date_list))\n",
    "        #print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "        \n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7300aa-372b-46f0-b103-7f604b8e6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9f6a8d-4312-405a-ae58-b7780cf54a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "# Create Folders\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1d202-91c0-4370-a8e8-bc8e249d4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596d7a7-993b-4c30-bc42-553037e042bb",
   "metadata": {},
   "source": [
    "## Implement DRL Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebee8b4",
   "metadata": {},
   "source": [
    "## Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85d9984-02a4-4b7d-a5fc-a91b79448760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222f96b-c7ac-4835-89e8-bda73cd305bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)\n",
    "\n",
    "trained_a2c.save('./trained_models/trained_a2c.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee251f32-bc06-474d-8986-853f54cfdddb",
   "metadata": {},
   "source": [
    "## Model 2: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bd1e3-9ba3-487e-832c-74f6cb23fd18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=80000)\n",
    "\n",
    "trained_ppo.save('./trained_models/trained_ppo.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473de05e-0a65-4b4c-b758-1776ab10c736",
   "metadata": {},
   "source": [
    "## Model 3: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60369ec-4bd3-4d52-b46d-77bc43074da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)\n",
    "\n",
    "trained_ddpg.save('./trained_models/trained_ddpg.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30597b1",
   "metadata": {},
   "source": [
    "## Model 3: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC \n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "\n",
    "# Параметры, специфичные для ПОЛИТИКИ (архитектура сети)\n",
    "POLICY_KWARGS = dict(net_arch=[256, 256])\n",
    "\n",
    "# ОСНОВНЫЕ параметры модели SAC (все остальное)\n",
    "MODEL_KWARGS = {\n",
    "    \"buffer_size\": 100000,\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"gamma\": 0.99,\n",
    "    \"tau\": 0.005,\n",
    "    \"ent_coef\": 'auto',\n",
    "    \"learning_starts\": 10000\n",
    "    # policy_kwargs УБРАН ОТСЮДА\n",
    "}\n",
    "\n",
    "\n",
    "model_sac = agent.get_model(\n",
    "    \"sac\",\n",
    "    policy_kwargs=POLICY_KWARGS, \n",
    "    model_kwargs=MODEL_KWARGS   \n",
    ")\n",
    "\n",
    "\n",
    "trained_sac = agent.train_model(\n",
    "    model=model_sac,\n",
    "    tb_log_name='sac',\n",
    "    total_timesteps=100000\n",
    ")\n",
    "\n",
    "\n",
    "trained_sac.save('./trained_models/trained_sac.zip')\n",
    "\n",
    "print(\"Модель SAC успешно создана, обучена и сохранена.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a126d-3096-42f3-af3c-c5832b465e3f",
   "metadata": {},
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c30492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Musonda2day/Asset-Portfolio-Management-usingDeep-Reinforcement-Learning-/blob/main/8.%20DRL_Portfolios.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f052024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rathiromil13/DS-5500-Project-Portfolio-Optimization-Using-Deep-Reinforcement-Learning/blob/master/documents/Final_Report_Portfolio_Optimization_using_Deep_Reinforcement_Learning.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f82b3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Конфигурация\n",
    "DATA_DIR = \"../data\"\n",
    "MODELS_PREDICTION_DIR = os.path.join(DATA_DIR, \"models_predictions\")\n",
    "\n",
    "# Создание папки для сохранения результатов\n",
    "os.makedirs(MODELS_PREDICTION_DIR, exist_ok=True)\n",
    "\n",
    "def evaluate_and_save_models(models, df, env_kwargs):\n",
    "    \"\"\"\n",
    "    Оценивает модели и сохраняет результаты в CSV файлы.\n",
    "\n",
    "    Параметры:\n",
    "        models (dict): Словарь с моделями, где ключ - название модели, значение - объект модели.\n",
    "        df (pd.DataFrame): Исходный DataFrame с данными.\n",
    "        env_kwargs (dict): Параметры для создания среды StockPortfolioEnv.\n",
    "\n",
    "    Возвращает:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Разделение данных на тестовый период\n",
    "    trade_data = data_split(df, start_test, end_test)\n",
    "    print(f\"Тестовые данные: {trade_data.shape}\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Обработка модели: {model_name}\")\n",
    "        try:\n",
    "            # Создание среды для торговли\n",
    "            trade_env = StockPortfolioEnv(df=trade_data, **env_kwargs)\n",
    "\n",
    "            # Получение предсказаний модели\n",
    "            df_daily_return, df_actions = DRLAgent.DRL_prediction(\n",
    "                model=model,\n",
    "                environment=trade_env\n",
    "            )\n",
    "\n",
    "            # Убедимся, что столбец 'date' имеет формат datetime\n",
    "            if 'date' in df_daily_return.columns:\n",
    "                df_daily_return['date'] = pd.to_datetime(df_daily_return['date'])\n",
    "\n",
    "            # Сохранение результатов\n",
    "            save_model_predictions(\n",
    "                df_daily_return=df_daily_return,\n",
    "                df_actions=df_actions,\n",
    "                model_name=model_name,\n",
    "                data_dir=DATA_DIR\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке модели {model_name}: {e}\")\n",
    "\n",
    "def save_model_predictions(df_daily_return, df_actions, model_name, data_dir):\n",
    "    \"\"\"\n",
    "    Сохраняет результаты предсказаний модели (доходность и действия) в CSV файлы.\n",
    "\n",
    "    Параметры:\n",
    "        df_daily_return (pd.DataFrame): DataFrame с ежедневной доходностью.\n",
    "        df_actions (pd.DataFrame): DataFrame с действиями модели.\n",
    "        model_name (str): Название модели (используется в имени файла).\n",
    "        data_dir (str): Путь к папке data.\n",
    "\n",
    "    Возвращает:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Путь к папке для сохранения файлов\n",
    "    models_prediction_dir = os.path.join(data_dir, \"models_predictions\")\n",
    "\n",
    "    # Имена файлов\n",
    "    return_file_name = os.path.join(models_prediction_dir, f\"{model_name}_return_series.csv\")\n",
    "    actions_file_name = os.path.join(models_prediction_dir, f\"{model_name}_actions.csv\")\n",
    "\n",
    "    try:\n",
    "        # Сохранение DataFrame с ежедневной доходностью\n",
    "        df_daily_return.to_csv(return_file_name, index=False)\n",
    "        print(f\"Файл '{return_file_name}' успешно сохранен.\")\n",
    "\n",
    "        # Сохранение DataFrame с действиями модели\n",
    "        df_actions.to_csv(actions_file_name, index=True)\n",
    "        print(f\"Файл '{actions_file_name}' успешно сохранен.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении файлов для модели {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"model_a2c\": model_a2c,\n",
    "    \"model_ppo\": model_ppo,\n",
    "    \"model_ddpg\": model_ddpg,\n",
    "    \"model_sac\": model_sac\n",
    "}\n",
    "\n",
    "\n",
    "# Вызов функции для оценки и сохранения результатов моделей\n",
    "evaluate_and_save_models(models=models, df=df, env_kwargs=env_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
