import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
from datetime import datetime, timedelta, date, time
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import traceback
import json
import requests
import time

# --- ADDED: Import pipeline ---
import torch

# --- Backend API Configuration ---
BACKEND_API_URL = os.getenv("BACKEND_API_URL", "http://localhost:8000/api/v1")

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (These will be gradually replaced by API calls)
from app_pages import (
    render_dashboard, 
    render_portfolio_optimization, 
    render_model_training, 
    render_model_comparison, 
    render_backtest,
    render_account_dashboard,
    render_transactions_manager,
    render_about
)

# --- Helper Functions (To be refactored or removed) ---

# --- NEW: Authentication functions using FastAPI backend ---
def initialize_users_file():
    # This function is no longer needed as user management is handled by the backend.
    pass

def register_user(username, password, email):
    """Registers a new user by calling the backend API."""
    try:
        response = requests.post(
            f"{BACKEND_API_URL}/auth/register",
            json={"username": username, "email": email, "password": password}
        )
        if response.status_code == 201: # FastAPI returns 201 for created
            return True, "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ! –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –≤–æ–π—Ç–∏."
        else:
            error_detail = response.json().get("detail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏.")
            return False, f"–û—à–∏–±–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {error_detail}"
    except requests.exceptions.RequestException as e:
        return False, f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º: {e}"

def authenticate_user(username, password):
    """Authenticates a user by calling the backend API."""
    try:
        response = requests.post(
            f"{BACKEND_API_URL}/auth/login/access-token",
            data={"username": username, "password": password} # FastAPI expects form data for token endpoint
        )
        if response.status_code == 200:
            data = response.json()
            st.session_state.access_token = data.get("access_token")
            st.session_state.refresh_token = data.get("refresh_token")
            st.session_state.token_type = data.get("token_type", "bearer")
            return True, "–í—Ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!"
        elif response.status_code == 401:
             error_detail = response.json().get("detail", "–ù–µ–≤–µ—Ä–Ω—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
             return False, f"–û—à–∏–±–∫–∞ –≤—Ö–æ–¥–∞: {error_detail}"
        else:
            error_detail = response.json().get("detail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –≤—Ö–æ–¥–∞.")
            return False, f"–û—à–∏–±–∫–∞ –≤—Ö–æ–¥–∞ (–∫–æ–¥ {response.status_code}): {error_detail}"
    except requests.exceptions.RequestException as e:
        return False, f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º: {e}"

def get_user_info(username): # username argument might become redundant if using token
    """Fetches user information from the backend API using the stored token."""
    if "access_token" not in st.session_state:
        return None # Or raise an error, or redirect to login

    headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
    try:
        response = requests.get(f"{BACKEND_API_URL}/users/me", headers=headers)
        if response.status_code == 200:
            user_data = response.json()
            # Adapt backend user data to the structure previously expected by Streamlit if necessary
            # For example, if Streamlit expects 'created_at', 'last_login'
            return {
                "username": user_data.get("username"),
                "email": user_data.get("email"),
                "is_active": user_data.get("is_active"),
                "is_superuser": user_data.get("is_superuser"),
                "id": user_data.get("id"),
                # Placeholder for fields that might have been in the old local user file
                "created_at": user_data.get("created_at", datetime.now().isoformat()), # Or fetch from backend if available
                "last_login": user_data.get("last_login", datetime.now().isoformat())  # Or fetch from backend if available
            }
        else:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∫–æ–¥ {response.status_code}): {response.text}")
            # Potentially handle token refresh here if 401 Unauthorized
            return None
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {e}")
        return None
# --- End NEW Authentication functions ---


# --- Functions to be refactored to use API calls ---
def get_user_portfolios(username): # To be refactored
    # This function might be deprecated if we only manage one portfolio per user via /portfolios/me
    st.warning("get_user_portfolios needs to be refactored or deprecated.")
    return []

def get_user_portfolio(username, portfolio_name): # To be refactored
    # This function might be deprecated if we only manage one portfolio per user via /portfolios/me
    st.warning("get_user_portfolio needs to be refactored or deprecated.")
    return None

def get_portfolio_with_quantities(username): # Refactored
    """Fetches the current user's portfolio summary from the backend API."""
    if "access_token" not in st.session_state:
        st.error("User not authenticated. Cannot fetch portfolio.")
        return {"quantities": {}, "avg_prices": {}, "current_prices": {}}

    headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
    try:
        # Assuming backend provides a summary endpoint for the authenticated user's portfolio
        # This endpoint should return quantities, average buy prices, and ideally current prices
        response = requests.get(f"{BACKEND_API_URL}/portfolios/me/summary", headers=headers)
        if response.status_code == 200:
            data = response.json()
            # Expected backend response structure:
            # {
            #   "assets": [
            #     { "ticker": "BTCUSDT", "quantity": 0.5, "average_buy_price": 30000, "current_price": 60000 },
            #     { "ticker": "ETHUSDT", "quantity": 10, "average_buy_price": 2000, "current_price": 3000 }
            #   ],
            #   "total_value": 33000,
            #   "total_pnl": ...
            # }
            # We need to transform this into the old structure expected by the Streamlit page for now.
            quantities = {}
            avg_prices = {}
            current_prices = {} # Add a dictionary for current prices from backend
            for asset_data in data.get("assets", []):
                ticker = asset_data.get("ticker")
                if ticker:
                    quantities[ticker] = asset_data.get("quantity", 0)
                    avg_prices[ticker] = asset_data.get("average_buy_price", 0)
                    current_prices[ticker] = asset_data.get("current_price", 0) # Store current price
            
            # The Streamlit UI calculates P&L and total value, so we primarily need these raw components.
            # If the backend provides total_value, total_pnl, daily_change, it can be used directly too.
            st.session_state.portfolio_summary_from_api = data # Store full summary for potential later use
            return {"quantities": quantities, "avg_prices": avg_prices, "current_prices": current_prices}
        elif response.status_code == 401:
            st.error("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞ –∏–ª–∏ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ–π–¥–∏—Ç–µ —Å–Ω–æ–≤–∞.")
            logout() # Force logout
            st.rerun()
            return {"quantities": {}, "avg_prices": {}, "current_prices": {}}
        else:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è (–∫–æ–¥ {response.status_code}): {response.text}")
            return {"quantities": {}, "avg_prices": {}, "current_prices": {}}
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}")
        return {"quantities": {}, "avg_prices": {}, "current_prices": {}}

def get_user_transactions(username): # Refactored
    """Fetches user's transactions from the backend API."""
    if "access_token" not in st.session_state:
        st.error("User not authenticated. Cannot fetch transactions.")
        return []

    headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
    try:
        # Assuming backend provides transactions for the authenticated user
        response = requests.get(f"{BACKEND_API_URL}/portfolios/me/transactions", headers=headers)
        if response.status_code == 200:
            transactions_list = response.json()
            # Convert date strings from API (e.g., ISO format) to datetime objects
            for tx in transactions_list:
                if 'created_at' in tx and isinstance(tx['created_at'], str):
                    tx['date'] = datetime.fromisoformat(tx['created_at'].replace('Z', '+00:00'))
                # Ensure other fields like quantity, price, fee are correct type (e.g. float)
                tx['quantity'] = float(tx.get('quantity', 0))
                tx['price'] = float(tx.get('price', 0))
                tx['fee'] = float(tx.get('fee', 0))
                # The backend model uses 'asset_ticker', Streamlit old code used 'asset'
                if 'asset_ticker' in tx and 'asset' not in tx:
                    tx['asset'] = tx['asset_ticker']
                if 'transaction_type' in tx and 'type' not in tx:
                     tx['type'] = tx['transaction_type']
            return transactions_list
        elif response.status_code == 401:
            st.error("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞ –∏–ª–∏ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ–π–¥–∏—Ç–µ —Å–Ω–æ–≤–∞.")
            logout()
            st.rerun()
            return []
        else:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (–∫–æ–¥ {response.status_code}): {response.text}")
            return []
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {e}")
        return []

def update_user_portfolio(username, portfolio_data): # To be refactored
    # This function is likely superseded by adding individual transactions via API
    st.warning("update_user_portfolio is likely deprecated. Add transactions instead.")
    pass
# --- End Functions to be refactored ---

# --- END HELPER FUNCTIONS ---

# <<< NEW: Dummy function for fetching news - REPLACE WITH REAL IMPLEMENTATION >>>
def fetch_dummy_news(asset_ticker):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏. –ó–∞–º–µ–Ω–∏—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π."""
    st.warning(f"–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è **–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ** –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {asset_ticker}.")
    # –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
    if asset_ticker == "BTCUSDT":
        return f"Bitcoin (BTCUSDT) price surged above $70,000 amid growing institutional interest. Several large investment firms announced new Bitcoin ETF filings. However, some analysts warn of potential volatility ahead of the upcoming halving event. The overall market sentiment remains cautiously optimistic. Key players like MicroStrategy continue to add to their BTC holdings."
    elif asset_ticker == "ETHUSDT":
        return f"Ethereum (ETHUSDT) saw moderate gains, following the general market trend. Discussions around the potential approval of an Ethereum Spot ETF continue, but regulatory uncertainty persists. Network activity remains high, driven by DeFi and NFT sectors. Vitalik Buterin recently commented on the importance of Layer 2 scaling solutions."
    else:
        return f"General market news for {asset_ticker}: Crypto markets experienced mixed trading today. Regulatory developments in the US and Asia are being closely watched by investors. Stablecoin regulations are also a hot topic. Overall trading volume was moderate."
# <<< END DUMMY NEWS FUNCTION >>>

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä Pro",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# <<< Add the missing function definition here >>>
# Function to load combined data with caching
# Use a parameter that changes upon update to invalidate cache
@st.cache_data
def load_combined_data_cached(update_trigger):
    """Loads combined data from CSV, using update_trigger for cache invalidation."""
    print(f"Cache Trigger: {update_trigger}. Loading combined data...") # Debug print
    combined_data_path = os.path.join("data", "data_compare_eda.csv")
    if os.path.exists(combined_data_path):
        try:
            combined_df = pd.read_csv(combined_data_path, index_col=0, parse_dates=True)
            # Ensure index is DatetimeIndex
            if not isinstance(combined_df.index, pd.DatetimeIndex):
                 combined_df.index = pd.to_datetime(combined_df.index, errors='coerce')
                 combined_df = combined_df.dropna(axis=0, subset=[combined_df.index.name]) # Drop rows if date parse failed
            combined_df.sort_index(inplace=True)
            print(f"Loaded {combined_data_path}, shape: {combined_df.shape}")
            return combined_df
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {combined_data_path}: {e}")
            return pd.DataFrame()
    else:
        st.warning(f"–§–∞–π–ª {combined_data_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return pd.DataFrame()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (No longer needed)
# initialize_users_file()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if 'authenticated' not in st.session_state: st.session_state.authenticated = False
if 'username' not in st.session_state: st.session_state.username = ""
if 'access_token' not in st.session_state: st.session_state.access_token = ""
if 'active_page' not in st.session_state: st.session_state.active_page = "–ì–ª–∞–≤–Ω–∞—è"
if 'user_info' not in st.session_state: st.session_state.user_info = None
if 'portfolio_summary' not in st.session_state: st.session_state.portfolio_summary = None
if 'transactions' not in st.session_state: st.session_state.transactions = []
if 'assets' not in st.session_state: st.session_state.assets = [] # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ –∞–∫–∫–∞—É–Ω—Ç–∞
def logout():
    st.session_state.authenticated = False
    st.session_state.username = None
    st.session_state.active_page = "–ì–ª–∞–≤–Ω–∞—è"
    st.session_state.login_message = "–í—ã –≤—ã—à–ª–∏ –∏–∑ —Å–∏—Å—Ç–µ–º—ã"
    # Clear analysis results on logout
    if 'analysis_results' in st.session_state: del st.session_state['analysis_results']
    if 'analysis_figure' in st.session_state: del st.session_state['analysis_figure']
    # Clear API tokens
    if 'access_token' in st.session_state: del st.session_state['access_token']
    if 'refresh_token' in st.session_state: del st.session_state['refresh_token']
    if 'token_type' in st.session_state: del st.session_state['token_type']

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
@st.cache_data(ttl=3600) # Cache for 1 hour
def load_app_data(): # Renamed to avoid conflict if there was an old load_data
    """Loads data required globally by the application, e.g., list of all available assets."""
    headers = {}
    if "access_token" in st.session_state: # Send token if available, some endpoints might be protected
        headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
    
    all_assets_list = []
    try:
        response = requests.get(f"{BACKEND_API_URL}/assets/", headers=headers)
        response.raise_for_status()
        assets_raw = response.json()
        all_assets_list = [asset.get("ticker_symbol") for asset in assets_raw if asset.get("ticker_symbol")]
    except requests.exceptions.RequestException as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–æ–≤: {e}")
        # Fallback or empty list
    
    # For price_data: This was used to get current prices. 
    # The new /portfolios/me/summary provides current prices for portfolio assets.
    # For other assets (e.g., for selection in optimization), we might need a different approach.
    # For now, let's assume `all_assets_list` is what we need for asset dropdowns.
    # A comprehensive `price_data` DataFrame with historical data for ALL assets is too large to load globally.
    # It should be fetched on-demand by specific pages.
    # So, the old `price_data` DataFrame is largely replaced by targeted API calls.
    
    # What was price_data used for? Primarily:
    # 1. Populating asset selectors (now use all_assets_list)
    # 2. Getting current price for P&L in –ú–æ–π –∫–∞–±–∏–Ω–µ—Ç (now from /me/summary)
    # 3. Getting current price for P&L in –ï–¢–ê (now from /me/summary or historical API)
    # 4. Potentially by optimization/analysis pages (these should fetch their own required data)
    
    # Therefore, the global price_data, model_returns, model_actions can be deprecated or changed.
    # We will return the list of asset tickers for now.
    st.session_state.all_available_tickers = all_assets_list

    # model_returns and model_actions were for model comparison.
    # This data should be fetched from specific backend endpoints when on those pages.
    # For now, returning empty placeholders for them.
    model_returns_placeholder = pd.DataFrame()
    model_actions_placeholder = pd.DataFrame()

    # The global price_data pandas DataFrame is problematic with API-first approach.
    # We'll return the list of tickers, and pages can fetch prices as needed.
    # For compatibility, some old sections might try to use `assets` which was price_data.columns
    # We'll set st.session_state.assets directly from all_available_tickers
    st.session_state.assets = all_assets_list

    # Return empty dataframes for the old tuple to avoid breaking too much code immediately
    # These will be gradually removed.
    return pd.DataFrame(columns=all_assets_list), model_returns_placeholder, model_actions_placeholder

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Call the new function)
# price_data, model_returns, model_actions = load_data() # Old call
price_data_global, model_returns_global, model_actions_global = load_app_data() 

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤
# assets = price_data.columns.tolist() if not price_data.empty else [] # Old way
# Now use the session state set by load_app_data or the first element of the returned tuple
assets = st.session_state.get("assets", [])
if not assets and not price_data_global.empty:
    assets = price_data_global.columns.tolist()

# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("Investment Portfolio Monitoring & Optimization System")

# –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
if not st.session_state.authenticated:
    # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –≤—Ö–æ–¥–∞ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    tab1, tab2 = st.tabs(["–í—Ö–æ–¥", "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è"])
    
    # –í–∫–ª–∞–¥–∫–∞ –≤—Ö–æ–¥–∞
    with tab1:
        st.header("–í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
        
        # –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞
        with st.form("login_form"):
            username = st.text_input("–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
            submit_button = st.form_submit_button("–í–æ–π—Ç–∏")
            
            if submit_button:
                success, message = authenticate_user(username, password)
                
                if success:
                    st.session_state.authenticated = True
                    st.session_state.username = username
                    st.session_state.active_page = "–ú–æ–π –∫–∞–±–∏–Ω–µ—Ç"
                    st.success(message)
                    st.rerun()
                else:
                    st.error(message)
        
        # –°–æ–æ–±—â–µ–Ω–∏–µ –æ –≤—ã—Ö–æ–¥–µ –∏–ª–∏ –æ—à–∏–±–∫–µ
        if st.session_state.login_message:
            st.info(st.session_state.login_message)
            st.session_state.login_message = None
    
    # –í–∫–ª–∞–¥–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    with tab2:
        st.header("–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        
        # –§–æ—Ä–º–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        with st.form("register_form"):
            new_username = st.text_input("–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            new_password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
            confirm_password = st.text_input("–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–∞—Ä–æ–ª—è", type="password")
            email = st.text_input("Email")
            register_button = st.form_submit_button("–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è")
            
            if register_button:
                if not new_username or not new_password:
                    st.error("–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø–∞—Ä–æ–ª—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã")
                elif new_password != confirm_password:
                    st.error("–ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
                else:
                    success, message = register_user(new_username, new_password, email)
                    
                    if success:
                        st.success(message)
                        st.info("–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –≤–æ–π—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º—É")
                    else:
                        st.error(message)

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
else:
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    st.sidebar.header(f"–ü—Ä–∏–≤–µ—Ç, {st.session_state.username}!")
    
    # –ö–Ω–æ–ø–∫–∞ –≤—ã—Ö–æ–¥–∞ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    if st.sidebar.button("–í—ã–π—Ç–∏"):
        logout()
        st.rerun()
    
    # –ú–µ–Ω—é –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    st.sidebar.header("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    page_options = [
        "–ú–æ–π –∫–∞–±–∏–Ω–µ—Ç", 
        "–î–∞–Ω–Ω—ã–µ –∏ –ê–Ω–∞–ª–∏–∑", 
        "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", # Added "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"
        "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏", 
        "–ï–¥–∏–Ω—ã–π —Ç–æ—Ä–≥–æ–≤—ã–π –∞–∫–∫–∞—É–Ω—Ç", 
        "–ê–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è", 
        "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
    ]
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è radio –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π –∞–∫—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–µ—Å—Å–∏–∏
    try:
        if st.session_state.active_page not in page_options:
            st.session_state.active_page = page_options[0]
        current_page_index = page_options.index(st.session_state.active_page)
    except ValueError:
        current_page_index = 0
        st.session_state.active_page = page_options[0]

    selected_page = st.sidebar.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª",
        page_options,
        index=current_page_index,
        key="main_nav_radio"
    )
    
    if selected_page != st.session_state.active_page:
        st.session_state.active_page = selected_page
        st.rerun()

    # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ª–∏—á–Ω–æ–≥–æ –∫–∞–±–∏–Ω–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if st.session_state.active_page == "–ú–æ–π –∫–∞–±–∏–Ω–µ—Ç":
        st.header("–õ–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (already uses API)
        user_info = get_user_info(st.session_state.username)

        if user_info:
            col1, col2 = st.columns([1, 2])

            with col1:
                st.subheader("–í–∞—à –ø—Ä–æ—Ñ–∏–ª—å")
                st.write(f"**Email:** {user_info.get('email', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
                # Assuming 'created_at' and 'last_login' are provided by backend's /users/me or are placeholders
                created_at_str = user_info.get('created_at', '')
                last_login_str = user_info.get('last_login', '')
                try:
                    created_at_dt = datetime.fromisoformat(created_at_str.replace('Z', '+00:00')) if created_at_str else None
                    last_login_dt = datetime.fromisoformat(last_login_str.replace('Z', '+00:00')) if last_login_str else None
                    st.write(f"**–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏:** {created_at_dt.strftime('%Y-%m-%d %H:%M:%S') if created_at_dt else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}")
                    st.write(f"**–ü–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ö–æ–¥:** {last_login_dt.strftime('%Y-%m-%d %H:%M:%S') if last_login_dt else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}")
                except ValueError:
                    st.write(f"**–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏:** {created_at_str}")
                    st.write(f"**–ü–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ö–æ–¥:** {last_login_str}")

            st.subheader("–í–∞—à–∏ –ø–æ—Ä—Ç—Ñ–µ–ª–∏")

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ—Ä—Ç—Ñ–µ–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ API
            portfolio_summary = get_portfolio_with_quantities(st.session_state.username)
            portfolio_quantities = portfolio_summary.get("quantities", {})
            portfolio_avg_prices = portfolio_summary.get("avg_prices", {})
            portfolio_current_prices = portfolio_summary.get("current_prices", {}) # Use current prices from API

            has_assets = portfolio_quantities and any(q > 0 for q in portfolio_quantities.values())

            if has_assets:
                portfolio_items = []
                total_portfolio_value = 0
                total_invested_value = 0 # For calculating total P&L

                # --- Temporarily load all price data for assets in portfolio for 24h change --- 
                # This should be replaced by a more efficient backend call for 24h price data
                assets_in_portfolio = [asset for asset, quantity in portfolio_quantities.items() if quantity > 0]
                # For now, we assume portfolio_current_prices has the latest prices
                # The 24h change calculation will need adjustment or a dedicated API field.
                # Placeholder for price_data which used to be global
                # For now, we will rely on current_price from the API summary for most calculations.
                # The 24h change metric might be inaccurate or disabled until price_data fetching is fully refactored.
                
                # --- Fallback: if portfolio_current_prices is empty, try to use global price_data (old way, to be removed) ---
                # This is a temporary bridge. The API should ideally provide all necessary price points.
                temp_price_data_holder = {}
                if not portfolio_current_prices and not price_data_global.empty: # price_data is from global load_data()
                    st.warning("Using stale global price_data for current prices as API did not provide them. This will be removed.")
                    for asset in assets_in_portfolio:
                        if asset in price_data_global.columns:
                            temp_price_data_holder[asset] = price_data_global[asset].iloc[-1]
                            # For 24h change, we'd need price_data[asset].iloc[-2] too
                elif not portfolio_current_prices:
                    st.error("Current prices not available from API and no fallback global price data. Values will be zero.")
                # --- End Fallback ---

                for asset, quantity in portfolio_quantities.items():
                    if quantity > 0:
                        current_price = portfolio_current_prices.get(asset, temp_price_data_holder.get(asset, 0))
                        avg_buy_price = portfolio_avg_prices.get(asset, 0)

                        current_value = quantity * current_price
                        invested_value = quantity * avg_buy_price
                        profit_loss = current_value - invested_value
                        profit_loss_percent = (profit_loss / invested_value * 100) if invested_value > 0 else 0

                        total_portfolio_value += current_value
                        total_invested_value += invested_value

                        portfolio_items.append({
                            "–ê–∫—Ç–∏–≤": asset,
                            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": quantity,
                            "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø–æ–∫—É–ø–∫–∏": avg_buy_price,
                            "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞": current_price,
                            "–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å": current_value,
                            "P&L": profit_loss,
                            "P&L (%)": profit_loss_percent
                        })
                
                total_profit_loss = total_portfolio_value - total_invested_value

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è", f"${total_portfolio_value:,.2f}")
                with col2:
                    delta_value = (total_profit_loss / total_invested_value * 100) if total_invested_value > 0 else 0
                    st.metric("–û–±—â–∏–π P&L", 
                              f"${total_profit_loss:,.2f}", 
                              delta=f"{delta_value:.2f}%" if total_invested_value else None,
                              delta_color="normal" if total_profit_loss >=0 else "inverse")
                
                with col3:
                    # 24h Change: This needs to be provided by the backend or fetched efficiently.
                    # Using a placeholder or a note that it's unavailable for now.
                    # If st.session_state.portfolio_summary_from_api has this info, use it:
                    change_24h_value_abs = st.session_state.get('portfolio_summary_from_api', {}).get('total_value_24h_change_abs')
                    change_24h_value_pct = st.session_state.get('portfolio_summary_from_api', {}).get('total_value_24h_change_pct')
                    if change_24h_value_abs is not None and change_24h_value_pct is not None:
                         st.metric("–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 24—á", 
                                   f"${change_24h_value_abs:,.2f}", 
                                   delta=f"{change_24h_value_pct:.2f}%",
                                   delta_color="normal" if change_24h_value_abs >= 0 else "inverse")
                    else:
                        st.metric("–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 24—á", "N/A", delta="–¢—Ä–µ–±—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ API", delta_color="off")

                # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Ä—Ç—Ñ–µ–ª—è
                portfolio_df = pd.DataFrame(portfolio_items)
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∞–∫—Ç–∏–≤–æ–≤
                if not portfolio_df.empty:
                    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–µ–∫—É—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
                    portfolio_df = portfolio_df.sort_values("–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å", ascending=False)
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    formatted_df = portfolio_df.copy()
                    formatted_df["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"] = formatted_df["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"].apply(lambda x: f"{x:,.8f}")
                    formatted_df["–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø–æ–∫—É–ø–∫–∏"] = formatted_df["–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø–æ–∫—É–ø–∫–∏"].apply(lambda x: f"${x:,.2f}")
                    formatted_df["–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞"] = formatted_df["–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞"].apply(lambda x: f"${x:,.2f}")
                    formatted_df["–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å"] = formatted_df["–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å"].apply(lambda x: f"${x:,.2f}")
                    formatted_df["P&L"] = formatted_df["P&L"].apply(
                        lambda x: f"${x:,.2f}" if x >= 0 else f"-${abs(x):,.2f}"
                    )
                    formatted_df["P&L (%)"] = formatted_df["P&L (%)"].apply(
                        lambda x: f"+{x:.2f}%" if x > 0 else (f"{x:.2f}%" if x < 0 else "0.00%")
                    )
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                    st.dataframe(formatted_df, use_container_width=True)
                    
                    # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–æ–≤ –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                    st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
                    fig = px.pie(
                        portfolio_df,
                        values="–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å",
                        names="–ê–∫—Ç–∏–≤",
                        title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–æ —Ç–µ–∫—É—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.info("–ß—Ç–æ–±—ã –∏–∑–º–µ–Ω–∏—Ç—å —Å–æ—Å—Ç–∞–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è, –¥–æ–±–∞–≤—å—Ç–µ –∏–ª–∏ —É–¥–∞–ª–∏—Ç–µ –∞–∫—Ç–∏–≤—ã —á–µ—Ä–µ–∑ —Ä–∞–∑–¥–µ–ª '–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏'.")
            else:
                st.info("""
                –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –∞–∫—Ç–∏–≤–æ–≤ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ.
                
                –ß—Ç–æ–±—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—å:
                1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª '–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏'
                2. –ù–∞ –≤–∫–ª–∞–¥–∫–µ '–î–æ–±–∞–≤–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é' –¥–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–∏ –ø–µ—Ä–≤—ã–µ –∞–∫—Ç–∏–≤—ã
                3. –ü–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –ø–æ—Ä—Ç—Ñ–µ–ª—å —Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                
                –í–∞—à –ø–æ—Ä—Ç—Ñ–µ–ª—å –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –∑–¥–µ—Å—å –∏ –≤ —Ä–∞–∑–¥–µ–ª–µ '–ï–¥–∏–Ω—ã–π —Ç–æ—Ä–≥–æ–≤—ã–π –∞–∫–∫–∞—É–Ω—Ç'.
                """)
                
                # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —Ä–∞–∑–¥–µ–ª—É "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏"
                if st.button("–ü–µ—Ä–µ–π—Ç–∏ –∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∞–∫—Ç–∏–≤–∞–º–∏", key="goto_manage_assets_from_cabinet"):
                    st.session_state.active_page = "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏"
                    st.rerun()
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ")
    
    # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –µ–¥–∏–Ω–æ–≥–æ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ –≤ —Å—Ç–∏–ª–µ Bybit
    elif st.session_state.active_page == "–ï–¥–∏–Ω—ã–π —Ç–æ—Ä–≥–æ–≤—ã–π –∞–∫–∫–∞—É–Ω—Ç":
        st.header("–ï–¥–∏–Ω—ã–π —Ç–æ—Ä–≥–æ–≤—ã–π –∞–∫–∫–∞—É–Ω—Ç")
        st.markdown("--- ")

        # --- Imports for this page (some might be already at top) ---
        from collections import OrderedDict
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        import plotly.io as pio
        import plotly.express as px

        # --- Load User Transactions --- 
        username = st.session_state.username
        transactions_list = get_user_transactions(username)

        # Convert list of transactions to DataFrame
        if transactions_list:
             transactions_df_raw = pd.DataFrame(transactions_list)
             # Ensure correct dtypes after loading from JSON
             transactions_df_raw['date'] = pd.to_datetime(transactions_df_raw['date'])
             transactions_df_raw['quantity'] = pd.to_numeric(transactions_df_raw['quantity'])
             transactions_df_raw['price'] = pd.to_numeric(transactions_df_raw['price'])
             transactions_df_raw['fee'] = pd.to_numeric(transactions_df_raw.get('fee', 0))
             if 'total_cost' not in transactions_df_raw.columns:
                  transactions_df_raw['total_cost'] = transactions_df_raw['quantity'] * transactions_df_raw['price'] + transactions_df_raw['fee']
             else:
                   transactions_df_raw['total_cost'] = pd.to_numeric(transactions_df_raw['total_cost'])
             # Sort transactions chronologically - IMPORTANT
             transactions_df_raw = transactions_df_raw.sort_values(by='date').reset_index(drop=True)
        else:
            transactions_df_raw = pd.DataFrame()

        if transactions_df_raw.empty:
            st.info("–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π. –î–æ–±–∞–≤—å—Ç–µ –∏—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ '–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏'.")
            if st.button("–ü–µ—Ä–µ–π—Ç–∏ –∫ –£–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∞–∫—Ç–∏–≤–∞–º–∏", key="uta_goto_manage"):
                 st.session_state.active_page = "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏"
                 st.rerun()
            st.stop()

        # Filter only buy transactions for the core logic of the notebook
        # Note: Sell transactions are ignored in the notebook's P&L logic, only used for markers
        buy_transactions_df = transactions_df_raw[transactions_df_raw['type'] == 'buy'].copy()
        # We need an ID for each buy transaction for the logic
        buy_transactions_df['Purchase_ID'] = buy_transactions_df.index # Simple ID based on order

        if buy_transactions_df.empty:
            st.info("–í –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ–∫—É–ø–∫–∏. –ì—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏ P&L –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ—Å—Ç—Ä–æ–µ–Ω.")
            # We can still show current holdings based on all transactions
            # (Add logic here later if needed to show holdings even without buys)
            st.stop()

        # --- Calculate Current Holdings (based on ALL transactions) --- 
        holdings = {}
        for _, row in transactions_df_raw.iterrows():
            asset = row['asset']
            quantity = row['quantity']
            type = row['type']
            if asset not in holdings: holdings[asset] = 0
            if type == 'buy': holdings[asset] += quantity
            elif type == 'sell': holdings[asset] -= quantity
        current_holdings = {asset: q for asset, q in holdings.items() if q > 1e-9} # Tolerance
        required_assets = list(current_holdings.keys())

        if not required_assets:
            st.info("–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —É –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–æ–≤ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ.")
            st.stop()

        # --- Load Historical Data (To be replaced by API call) ---
        @st.cache_data(ttl=1800)
        def load_and_preprocess_historical_data_uta_api(assets_list, start_date_str=None, end_date_str=None, interval="1h"):
            st.info(f"UTA: Fetching historical data for {assets_list} from {start_date_str} to {end_date_str} ({interval}) from backend API...")
            if "access_token" not in st.session_state:
                st.error("Authentication token not found. Cannot fetch historical data.")
                return pd.DataFrame(), pd.Timestamp.now().tz_localize(None)
            
            headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
            params = {
                "tickers": assets_list,
                "start_date": start_date_str,
                "end_date": end_date_str,
                "interval": interval
            }
            
            try:
                response = requests.get(f"{BACKEND_API_URL}/assets/market-data/historical", headers=headers, params=params)
                response.raise_for_status() # Raises an exception for 4XX/5XX errors
                
                api_data = response.json()
                if not api_data:
                    st.warning("No historical data returned from API.")
                    return pd.DataFrame(), pd.Timestamp.now().tz_localize(None)

                # Convert API data (list of dicts) to DataFrame expected by the chart
                # Expected format: DateTimeIndex, columns: {ASSET_TICKER}_Price
                # API returns: list of {"ticker": "X", "timestamp": "T", "close": Y, ...}
                
                df_list = []
                for item in api_data:
                    df_list.append({
                        'date_index': pd.to_datetime(item['timestamp']),
                        'ticker': item['ticker'],
                        'price': item['close'] # Using 'close' price for the '_Price' column
                    })
                if not df_list:
                    st.warning("Processed API data is empty.")
                    return pd.DataFrame(), pd.Timestamp.now().tz_localize(None)

                temp_df = pd.DataFrame(df_list)
                # Pivot to get tickers as columns: {ASSET_TICKER}_Price
                pivot_df = temp_df.pivot_table(index='date_index', columns='ticker', values='price')
                # Rename columns to f'{ticker}_Price'
                pivot_df.columns = [f'{col}_Price' for col in pivot_df.columns]
                
                # Ensure index is sorted
                pivot_df.sort_index(inplace=True)
                
                min_date_from_data = pivot_df.index.min() if not pivot_df.empty else pd.Timestamp.now().tz_localize(None)
                st.success(f"Successfully fetched and processed {len(pivot_df)} data points for {len(assets_list)} assets.")
                return pivot_df, min_date_from_data

            except requests.exceptions.HTTPError as http_err:
                st.error(f"HTTP error fetching historical data: {http_err} - {response.text}")
                return pd.DataFrame(), pd.Timestamp.now().tz_localize(None)
            except requests.exceptions.RequestException as req_err:
                st.error(f"Request error fetching historical data: {req_err}")
                return pd.DataFrame(), pd.Timestamp.now().tz_localize(None)
            except Exception as e:
                st.error(f"Error processing historical data from API: {e}")
                traceback.print_exc()
                return pd.DataFrame(), pd.Timestamp.now().tz_localize(None)
        
        # Determine date range for historical data based on transactions or a default period
        oldest_tx_date = transactions_df_raw['date'].min() if not transactions_df_raw.empty else datetime.now() - timedelta(days=180)
        # Fetch data from a bit before the oldest transaction to today
        # Ensure dates are in ISO format strings for the API call
        api_start_date = (oldest_tx_date - timedelta(days=2)).isoformat()
        api_end_date = datetime.now().isoformat()

        historical_prices, earliest_data_date = load_and_preprocess_historical_data_uta_api(
            required_assets,
            start_date_str=api_start_date,
            end_date_str=api_end_date,
            interval="1h" # Default interval for now
        )

        if historical_prices.empty:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–∫—Ç–∏–≤–æ–≤ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ.")
            st.stop()

        # --- Calculate Metrics (Current State) --- 
        latest_prices = historical_prices.ffill().iloc[-1]
        prices_24h_ago = historical_prices.ffill().iloc[-25] if len(historical_prices) >= 25 else latest_prices
        
        total_balance = 0
        total_balance_24h_ago = 0
        current_holdings_list = []
        total_cost_basis_from_all_tx = 0 # Recalculate cost basis from raw transactions for accuracy
        temp_holdings_for_cost = {}
        for _, row in transactions_df_raw.iterrows():
            asset = row['asset']
            q = row['quantity']
            cost = row['total_cost']
            type = row['type']
            if asset not in temp_holdings_for_cost: temp_holdings_for_cost[asset] = {'q':0, 'cost':0}
            if type == 'buy': 
                temp_holdings_for_cost[asset]['q'] += q
                temp_holdings_for_cost[asset]['cost'] += cost
            elif type == 'sell':
                if temp_holdings_for_cost[asset]['q'] > 1e-9: # Check if holding exists
                    ratio = min(q / temp_holdings_for_cost[asset]['q'], 1.0)
                    temp_holdings_for_cost[asset]['cost'] *= (1 - ratio)
                    temp_holdings_for_cost[asset]['q'] -= q
                temp_holdings_for_cost[asset]['q'] = max(0, temp_holdings_for_cost[asset]['q'])
        total_cost_basis_from_all_tx = sum(d['cost'] for d in temp_holdings_for_cost.values() if d['q'] > 1e-9)

        for asset, quantity in current_holdings.items():
            current_price = latest_prices.get(f'{asset}_Price', 0)
            price_24h = prices_24h_ago.get(f'{asset}_Price', current_price)
            current_value = quantity * current_price
            value_24h = quantity * price_24h
            total_balance += current_value
            total_balance_24h_ago += value_24h
            current_holdings_list.append({"–ê–∫—Ç–∏–≤": asset, "–ö–æ–ª-–≤–æ": quantity, "–°—Ç–æ–∏–º–æ—Å—Ç—å (USD)": current_value})

        today_pnl_usd = total_balance - total_balance_24h_ago
        today_pnl_pct = (today_pnl_usd / total_balance_24h_ago * 100) if total_balance_24h_ago > 0 else 0
        total_pnl_usd = total_balance - total_cost_basis_from_all_tx
        total_pnl_pct = (total_pnl_usd / total_cost_basis_from_all_tx * 100) if total_cost_basis_from_all_tx > 0 else 0

        # --- Display Metrics --- 
        col1, col2, col3 = st.columns(3)
        with col1: st.metric("–ë–∞–ª–∞–Ω—Å –∞–∫–∫–∞—É–Ω—Ç–∞ (USD)", f"{total_balance:,.2f}")
        with col2: st.metric("P&L –∑–∞ —Å–µ–≥–æ–¥–Ω—è (USD)", f"{today_pnl_usd:,.2f}", delta=f"{today_pnl_pct:.2f}%", delta_color="normal" if today_pnl_usd >= 0 else "inverse")
        with col3: st.metric("–û–±—â–∏–π P&L –ø–æ—Ä—Ç—Ñ–µ–ª—è (USD)", f"{total_pnl_usd:,.2f}", delta=f"{total_pnl_pct:.2f}%", delta_color="normal" if total_pnl_usd >= 0 else "inverse")
        st.markdown("--- ")
        
        # --- Assets Overview --- 
        col_assets, col_chart_placeholder = st.columns([1, 2]) # Placeholder for chart area
        with col_assets:
            st.subheader("–ê–∫—Ç–∏–≤—ã")
            if current_holdings_list:
                holdings_df = pd.DataFrame(current_holdings_list)
                holdings_df["–î–æ–ª—è (%)"] = (holdings_df["–°—Ç–æ–∏–º–æ—Å—Ç—å (USD)"] / total_balance * 100).round(2) if total_balance > 0 else 0
                holdings_df = holdings_df.sort_values("–°—Ç–æ–∏–º–æ—Å—Ç—å (USD)", ascending=False)
                st.dataframe(holdings_df.style.format({"–ö–æ–ª-–≤–æ": "{:.6f}", "–°—Ç–æ–∏–º–æ—Å—Ç—å (USD)": "${:,.2f}", "–î–æ–ª—è (%)": "{:.2f}%"}), use_container_width=True)
            else: st.write("–ù–µ—Ç –∞–∫—Ç–∏–≤–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

        # --- Detailed Historical Calculation (from Notebook logic) ---
        st.markdown("--- ")
        st.subheader(f"–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        
        days_history_options = {"7 –¥–Ω–µ–π": 7, "30 –¥–Ω–µ–π": 30, "90 –¥–Ω–µ–π": 90, "180 –¥–Ω–µ–π": 180, "–í—Å–µ –≤—Ä–µ–º—è": None}
        selected_days_label = st.radio("–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:", days_history_options.keys(), index=3, horizontal=True, key="analysis_interval") # Default 180d
        selected_days = days_history_options[selected_days_label]
        
        report_date_viz = historical_prices.index.max()
        if selected_days:
            start_date_viz = report_date_viz - pd.Timedelta(days=selected_days)
        else:
            start_date_viz = transactions_df_raw['date'].min()
        start_date_viz = max(start_date_viz, earliest_data_date) # Ensure we don't go before data exists

        historical_prices_filtered = historical_prices[
            (historical_prices.index >= start_date_viz) &
            (historical_prices.index <= report_date_viz)
        ].copy()
        historical_prices_filtered = historical_prices_filtered.ffill().bfill().dropna(how='all')

        if historical_prices_filtered.empty:
            st.warning(f"–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ ({selected_days_label}).")
        else:
            # Find actual purchase prices within the *full* historical data for accuracy
            buy_transactions_df['Purchase_Price_Actual'] = np.nan
            buy_transactions_df['Actual_Purchase_Time_Index'] = pd.NaT
            for index, row in buy_transactions_df.iterrows():
                asset = row['asset']
                purchase_date = row['date']
                price_col = f'{asset}_Price'
                if price_col not in historical_prices.columns: continue
                relevant_prices_index = historical_prices.index[historical_prices.index >= purchase_date]
                if not relevant_prices_index.empty:
                    actual_purchase_time_index = relevant_prices_index[0]
                    try:
                        purchase_price = historical_prices.loc[actual_purchase_time_index, price_col]
                        if pd.notna(purchase_price) and purchase_price > 0:
                            buy_transactions_df.loc[index, 'Purchase_Price_Actual'] = purchase_price
                            buy_transactions_df.loc[index, 'Actual_Purchase_Time_Index'] = actual_purchase_time_index
                    except KeyError: pass # Ignore if time index not found exactly
            
            # Drop buys where we couldn't find a valid price/time
            buy_transactions_df.dropna(subset=['Actual_Purchase_Time_Index', 'Purchase_Price_Actual'], inplace=True)

            if buy_transactions_df.empty:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ–∫—É–ø–∫–∏ —Å —Ü–µ–Ω–∞–º–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ P&L.")
            else:
                # Calculate Cumulative Cost based *only* on the valid buys found
                historical_prices_filtered['Cumulative_Cost'] = 0.0
                for _, row in buy_transactions_df.iterrows():
                    cost = row['total_cost']
                    purchase_time = row['Actual_Purchase_Time_Index']
                    historical_prices_filtered.loc[historical_prices_filtered.index >= purchase_time, 'Cumulative_Cost'] += cost

                # Calculate individual value, P&L, contribution
                purchase_value_cols = []
                purchase_pnl_cols = []
                purchase_perc_contrib_cols = []
                purchase_labels = []
                
                with st.spinner("–†–∞—Å—á–µ—Ç –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è..."):
                    for index, purchase_row in buy_transactions_df.iterrows():
                        purchase_id = purchase_row['Purchase_ID']
                        asset = purchase_row['asset']
                        initial_investment = purchase_row['total_cost']
                        purchase_price = purchase_row['Purchase_Price_Actual']
                        purchase_time = purchase_row['Actual_Purchase_Time_Index']
                        price_col = f'{asset}_Price'
                        
                        if price_col not in historical_prices_filtered.columns: continue

                        value_col_name = f"Value_ID{purchase_id}_{asset}"
                        pnl_col_name = f"PnL_ID{purchase_id}_{asset}"
                        perc_contrib_col_name = f"PercContrib_ID{purchase_id}_{asset}"
                        label = f"{asset} (ID:{purchase_id}, ${initial_investment:,.2f})"

                        purchase_value_cols.append(value_col_name)
                        purchase_pnl_cols.append(pnl_col_name)
                        purchase_perc_contrib_cols.append(perc_contrib_col_name)
                        purchase_labels.append(label)

                        historical_prices_filtered[value_col_name] = 0.0
                        historical_prices_filtered[pnl_col_name] = 0.0
                        historical_prices_filtered[perc_contrib_col_name] = 0.0

                        mask = historical_prices_filtered.index >= purchase_time
                        if mask.any():
                            current_prices = historical_prices_filtered.loc[mask, price_col]
                            if pd.isna(purchase_price) or purchase_price <= 0:
                                price_ratio = pd.Series(0.0, index=current_prices.index)
                            else:
                                price_ratio = current_prices / purchase_price
                                price_ratio = price_ratio.fillna(0).replace([np.inf, -np.inf], 0)
                            current_purchase_value = initial_investment * price_ratio
                            historical_prices_filtered.loc[mask, value_col_name] = current_purchase_value
                            historical_prices_filtered.loc[mask, pnl_col_name] = current_purchase_value - initial_investment

                    # Sum up totals
                    historical_prices_filtered['Total_Value_Relative'] = historical_prices_filtered[purchase_value_cols].sum(axis=1)
                    historical_prices_filtered['Total_PnL'] = historical_prices_filtered['Total_Value_Relative'] - historical_prices_filtered['Cumulative_Cost']
                    
                    # Calculate percentage contributions
                    denom = historical_prices_filtered['Total_Value_Relative']
                    valid_denom_mask = np.abs(denom) > 1e-9
                    for pnl_col, perc_contrib_col in zip(purchase_pnl_cols, purchase_perc_contrib_cols):
                        percentage_contribution = np.zeros_like(denom)
                        percentage_contribution[valid_denom_mask] = (historical_prices_filtered.loc[valid_denom_mask, pnl_col] / denom[valid_denom_mask]) * 100
                        historical_prices_filtered[perc_contrib_col] = pd.Series(percentage_contribution, index=historical_prices_filtered.index).fillna(0)
                    
                    total_pnl_percentage = np.zeros_like(denom)
                    total_pnl_percentage[valid_denom_mask] = (historical_prices_filtered.loc[valid_denom_mask, 'Total_PnL'] / denom[valid_denom_mask]) * 100
                    historical_prices_filtered['Total_PnL_Percentage'] = pd.Series(total_pnl_percentage, index=historical_prices_filtered.index).fillna(0)

                # --- Plotting --- 
                pio.templates.default = "plotly_dark"
                fig = make_subplots(
                    rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.04,
                    subplot_titles=(
                        f'–°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è vs –í–ª–æ–∂–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞',
                        '–í–∫–ª–∞–¥ –∫–∞–∂–¥–æ–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –ê–±—Å–æ–ª—é—Ç–Ω—ã–π P&L',
                        '–í–∫–ª–∞–¥ P&L –∫–∞–∂–¥–æ–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ % –æ—Ç –û–±—â–µ–π –°—Ç–æ–∏–º–æ—Å—Ç–∏'
                    ))

                # Chart 1
                fig.add_trace(go.Scatter(x=historical_prices_filtered.index, y=historical_prices_filtered['Total_Value_Relative'], mode='lines', name='–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å', line=dict(color='#388BFF', width=2), hovertemplate='–î–∞—Ç–∞: %{x}<br>–°—Ç–æ–∏–º–æ—Å—Ç—å: %{y:,.2f} USDT<extra></extra>'), row=1, col=1)
                fig.add_trace(go.Scatter(x=historical_prices_filtered.index, y=historical_prices_filtered['Cumulative_Cost'], mode='lines', name='–í–ª–æ–∂–µ–Ω–æ —Å—Ä–µ–¥—Å—Ç–≤', line=dict(color='#AAAAAA', dash='dash', width=1.5), hovertemplate='–î–∞—Ç–∞: %{x}<br>–í–ª–æ–∂–µ–Ω–æ: %{y:,.2f} USDT<extra></extra>'), row=1, col=1)
                
                # Add markers for ALL transactions in range (Buys and Sells)
                transactions_in_plot_range = transactions_df_raw[transactions_df_raw['date'] >= historical_prices_filtered.index.min()]
                buy_markers = transactions_in_plot_range[transactions_in_plot_range['type'] == 'buy']
                sell_markers = transactions_in_plot_range[transactions_in_plot_range['type'] == 'sell']
                
                buy_marker_times = []
                buy_marker_values = []
                buy_marker_texts = []
                for _, row in buy_markers.iterrows():
                    # Find closest index <= transaction date
                    marker_time_idx = historical_prices_filtered.index[historical_prices_filtered.index <= row['date']]
                    if not marker_time_idx.empty:
                        marker_time = marker_time_idx[-1]
                        buy_marker_times.append(marker_time)
                        buy_marker_values.append(historical_prices_filtered.loc[marker_time, 'Total_Value_Relative'])
                        buy_marker_texts.append(f"<b>–ü–æ–∫—É–ø–∫–∞ {row['asset']}</b><br>–î–∞—Ç–∞: {row['date'].strftime('%Y-%m-%d %H:%M')}<br>–ö–æ–ª-–≤–æ: {row['quantity']:.6f}<br>–¶–µ–Ω–∞: ${row['price']:.2f}<br>–°—É–º–º–∞: ${row['total_cost']:,.2f}<extra></extra>")
                if buy_marker_times:
                     fig.add_trace(go.Scatter(x=buy_marker_times, y=buy_marker_values, mode='markers', name='–ü–æ–∫—É–ø–∫–∏', marker=dict(color='#00BFFF', size=7, symbol='triangle-up', line=dict(color='white', width=1)), hoverinfo='text', text=buy_marker_texts), row=1, col=1)

                sell_marker_times = []
                sell_marker_values = []
                sell_marker_texts = []
                for _, row in sell_markers.iterrows():
                     marker_time_idx = historical_prices_filtered.index[historical_prices_filtered.index <= row['date']]
                     if not marker_time_idx.empty:
                         marker_time = marker_time_idx[-1]
                         sell_marker_times.append(marker_time)
                         sell_marker_values.append(historical_prices_filtered.loc[marker_time, 'Total_Value_Relative'])
                         sell_marker_texts.append(f"<b>–ü—Ä–æ–¥–∞–∂–∞ {row['asset']}</b><br>–î–∞—Ç–∞: {row['date'].strftime('%Y-%m-%d %H:%M')}<br>–ö–æ–ª-–≤–æ: {row['quantity']:.6f}<br>–¶–µ–Ω–∞: ${row['price']:.2f}<br>–°—É–º–º–∞: ${row['total_cost']:,.2f}<extra></extra>")
                if sell_marker_times:
                    fig.add_trace(go.Scatter(x=sell_marker_times, y=sell_marker_values, mode='markers', name='–ü—Ä–æ–¥–∞–∂–∏', marker=dict(color='#FF6347', size=7, symbol='triangle-down', line=dict(color='white', width=1)), hoverinfo='text', text=sell_marker_texts), row=1, col=1)

                # Chart 2 - Absolute P&L Stack
                num_colors = len(purchase_labels)
                colors = px.colors.qualitative.T10
                if num_colors > len(colors): colors = colors * (num_colors // len(colors)) + colors[:num_colors % len(colors)]
                color_map = {label: colors[i] for i, label in enumerate(purchase_labels)}

                for i, (pnl_col, label) in enumerate(zip(purchase_pnl_cols, purchase_labels)):
                    color = color_map[label]
                    fig.add_trace(go.Scatter(x=historical_prices_filtered.index, y=historical_prices_filtered[pnl_col].fillna(0), mode='lines', name=label, stackgroup='pnl_absolute', line=dict(width=0), fillcolor=color, hovertemplate=f'<b>{label}</b><br>–î–∞—Ç–∞: %{{x}}<br>–ê–±—Å. P&L: %{{y:,.2f}} USDT<extra></extra>', legendgroup=label, showlegend=False), row=2, col=1)
                fig.add_trace(go.Scatter(x=historical_prices_filtered.index, y=historical_prices_filtered['Total_PnL'], mode='lines', name='–û–±—â–∏–π P&L', line=dict(color='white', dash='dot', width=2), hovertemplate='<b>–û–±—â–∏–π P&L</b><br>–î–∞—Ç–∞: %{x}<br>P&L: %{y:,.2f}} USDT<extra></extra>', legendgroup="total_pnl"), row=2, col=1)
                fig.add_hline(y=0, line_width=1, line_dash="solid", line_color="grey", row=2, col=1)

                # Chart 3 - Percentage P&L Stack
                for i, (perc_contrib_col, label) in enumerate(zip(purchase_perc_contrib_cols, purchase_labels)):
                    color = color_map[label]
                    fig.add_trace(go.Scatter(x=historical_prices_filtered.index, y=historical_prices_filtered[perc_contrib_col].fillna(0), mode='lines', name=label, stackgroup='pnl_percentage', line=dict(width=0), fillcolor=color, hovertemplate=f'<b>{label}</b><br>–î–∞—Ç–∞: %{{x}}<br>% –í–∫–ª–∞–¥ P&L: %{{y:.2f}}%<extra></extra>', legendgroup=label, showlegend=False), row=3, col=1)
                fig.add_trace(go.Scatter(x=historical_prices_filtered.index, y=historical_prices_filtered['Total_PnL_Percentage'], mode='lines', name='–û–±—â–∏–π P&L %', line=dict(color='white', dash='dot', width=2), hovertemplate='<b>–û–±—â–∏–π P&L %</b><br>–î–∞—Ç–∞: %{x}<br>P&L: %{y:.2f}%<extra></extra>', legendgroup="total_pnl_perc"), row=3, col=1)
                fig.add_hline(y=0, line_width=1, line_dash="solid", line_color="grey", row=3, col=1)

                # Layout updates
                fig.update_layout(
                    height=800, hovermode='x unified',
                    legend=dict(traceorder='normal', orientation='h', yanchor='bottom', y=1.01, xanchor='right', x=1),
                    margin=dict(l=50, r=20, t=60, b=50)
                )
                fig.update_xaxes(showline=True, linewidth=1, linecolor='grey', mirror=True, gridcolor='rgba(128, 128, 128, 0.2)')
                fig.update_yaxes(showline=True, linewidth=1, linecolor='grey', mirror=True, gridcolor='rgba(128, 128, 128, 0.2)', zeroline=False)
                fig.update_yaxes(title_text="–°—Ç–æ–∏–º–æ—Å—Ç—å (USDT)", tickprefix="$", row=1, col=1)
                fig.update_yaxes(title_text="–ê–±—Å. P&L (USDT)", tickprefix="$", row=2, col=1)
                fig.update_yaxes(title_text="% –í–∫–ª–∞–¥ P&L", ticksuffix="%", row=3, col=1)
                fig.update_xaxes(title_text="–î–∞—Ç–∞", row=3, col=1)

                st.plotly_chart(fig, use_container_width=True)

    # –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞–º–∏ –∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏
    elif st.session_state.active_page == "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏":
        render_transactions_manager(st.session_state.username, price_data_global, assets)
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ app_pages.py
    elif st.session_state.active_page == "–ê–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è":
        st.header("–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        st.markdown("–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –∫–∞–∫ –±—ã –∏–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤–∞—à–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è, \\n        –µ—Å–ª–∏ –±—ã –≤—ã —Å–ª–µ–¥–æ–≤–∞–ª–∏ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º.")

        # --- Session state initialization for this page ---
        if 'analysis_portfolio_id' not in st.session_state: st.session_state.analysis_portfolio_id = None
        if 'analysis_task_id' not in st.session_state: st.session_state.analysis_task_id = None
        if 'analysis_results' not in st.session_state: st.session_state.analysis_results = None
        if 'analysis_status_message' not in st.session_state: st.session_state.analysis_status_message = ""
        if 'analysis_error' not in st.session_state: st.session_state.analysis_error = None
        if 'last_polled_task_id' not in st.session_state: st.session_state.last_polled_task_id = None

        # --- Get current user's portfolio ID --- 
        if st.session_state.analysis_portfolio_id is None and "access_token" in st.session_state:
            headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
            try:
                response = requests.get(f"{BACKEND_API_URL}/portfolios/", headers=headers, params={"limit": 1})
                response.raise_for_status()
                portfolios = response.json()
                if portfolios and len(portfolios) > 0:
                    st.session_state.analysis_portfolio_id = portfolios[0].get("id")
                else:
                    st.session_state.analysis_status_message = "–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Ä—Ç—Ñ–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –°–æ–∑–¥–∞–π—Ç–µ –ø–æ—Ä—Ç—Ñ–µ–ª—å."
            except requests.exceptions.RequestException as e:
                st.session_state.analysis_error = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å ID –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}"
        
        if st.session_state.analysis_portfolio_id:
            st.info(f"–ê–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –¥–ª—è –≤–∞—à–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è ID: {st.session_state.analysis_portfolio_id}")
        elif not "access_token" in st.session_state:
            st.warning("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        else:
            st.warning(st.session_state.analysis_status_message or "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")

        # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ê–Ω–∞–ª–∏–∑–∞ --- 
        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
        today_date = datetime.now().date()
        default_start_date = today_date - timedelta(days=180)

        col1, col2 = st.columns(2)
        with col1:
             start_date_analysis = st.date_input("–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞", value=default_start_date, max_value=today_date - timedelta(days=1), key="analysis_start_date")
             commission_input = st.number_input("–ö–æ–º–∏—Å—Å–∏—è –∑–∞ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É (%)", min_value=0.0, max_value=5.0, value=0.1, step=0.01, format="%.3f", key="analysis_commission")
        with col2:
             end_date_analysis = st.date_input("–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞", value=today_date, min_value=start_date_analysis + timedelta(days=1) if start_date_analysis else None, key="analysis_end_date")
             initial_capital_analysis = st.number_input("–ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª (USD)", min_value=1.0, value=10000.0, step=100.0, format="%.2f", key="analysis_initial_capital")
        # Removed bank_apr, rebalance_interval, drl_rebalance_interval for simplicity, can be added to analysis_parameters if needed

        # --- –ö–Ω–æ–ø–∫–∞ –ó–∞–ø—É—Å–∫–∞ --- 
        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è (—á–µ—Ä–µ–∑ API)", use_container_width=True, disabled=(st.session_state.analysis_portfolio_id is None)):
            st.session_state.analysis_task_id = None 
            st.session_state.analysis_results = None
            st.session_state.analysis_error = None
            st.session_state.last_polled_task_id = None
            st.session_state.analysis_status_message = "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∞–Ω–∞–ª–∏–∑..."

            headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
            analysis_params_for_backend = {
                "start_date": start_date_analysis.isoformat() if start_date_analysis else None,
                "end_date": end_date_analysis.isoformat() if end_date_analysis else None,
                "initial_capital": initial_capital_analysis,
                "commission_rate": commission_input / 100.0,
                # Add other params like rebalance_interval if your backend task uses them
            }
            payload = {
                "portfolio_id": st.session_state.analysis_portfolio_id,
                "analysis_parameters": analysis_params_for_backend
            }
            try:
                response = requests.post(f"{BACKEND_API_URL}/portfolios/analyze", json=payload, headers=headers)
                response.raise_for_status()
                task_info = response.json()
                st.session_state.analysis_task_id = task_info.get("task_id")
                st.session_state.last_polled_task_id = st.session_state.analysis_task_id # Initialize for polling
                st.session_state.analysis_status_message = f"–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω. ID –ó–∞–¥–∞—á–∏: {st.session_state.analysis_task_id}. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞..."
                st.success(st.session_state.analysis_status_message)
                st.experimental_rerun() # Start polling immediately
            except requests.exceptions.HTTPError as http_err:
                st.session_state.analysis_error = f"HTTP –æ—à–∏–±–∫–∞: {http_err} - {response.text}"
            except requests.exceptions.RequestException as req_err:
                st.session_state.analysis_error = f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {req_err}"
            except Exception as e:
                st.session_state.analysis_error = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"
        
        # Polling for task status
        if st.session_state.analysis_task_id and st.session_state.analysis_task_id == st.session_state.last_polled_task_id and st.session_state.analysis_results is None and st.session_state.analysis_error is None:
            time.sleep(3) # Wait before polling
            headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
            try:
                status_response = requests.get(f"{BACKEND_API_URL}/utils/tasks/{st.session_state.analysis_task_id}", headers=headers)
                status_response.raise_for_status()
                task_status_data = status_response.json()
                status = task_status_data.get("status")
                result = task_status_data.get("result") 
                meta_info = task_status_data.get("meta", {})

                if status == "SUCCESS":
                    st.session_state.analysis_status_message = "–ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!"
                    st.session_state.analysis_results = result 
                    st.session_state.last_polled_task_id = None # Stop polling
                elif status == "FAILURE" or status == "REVOKED":
                    st.session_state.analysis_error = f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ (–°—Ç–∞—Ç—É—Å: {status}). –†–µ–∑—É–ª—å—Ç–∞—Ç: {result or meta_info.get('exc_message', '–ù–µ—Ç –¥–µ—Ç–∞–ª–µ–π')}"
                    st.session_state.last_polled_task_id = None # Stop polling
                elif status == "PROGRESS":
                    current_step = meta_info.get('current', '')
                    total_steps = meta_info.get('total', '')
                    step_status = meta_info.get('status', '–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è...')
                    progress_val = (current_step / total_steps) if isinstance(current_step, int) and isinstance(total_steps, int) and total_steps > 0 else 0
                    st.session_state.analysis_status_message = f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {step_status} ({current_step}/{total_steps})"
                    st.experimental_rerun() 
                else: # PENDING or other states
                    st.session_state.analysis_status_message = f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {status}. {meta_info.get('status', '–û–∂–∏–¥–∞–Ω–∏–µ...')}"
                    st.experimental_rerun() 
            except requests.exceptions.RequestException as req_err:
                st.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞: {req_err}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥...")
                st.experimental_rerun()
            except Exception as e:
                st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏: {e}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                st.experimental_rerun()
        
        # Display status or results
        if st.session_state.analysis_error:
            st.error(st.session_state.analysis_error)
        elif st.session_state.analysis_results:
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ê–Ω–∞–ª–∏–∑–∞ –ü–æ—Ä—Ç—Ñ–µ–ª—è (–∏–∑ API)")
            results_package = st.session_state.analysis_results
            metrics_data = results_package.get("metrics")
            if metrics_data:
                st.markdown("**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:**")
                # Assuming metrics_data is a dict like: {"period": "...", "final_value_buy_hold": ...}
                for key, value in metrics_data.items():
                    st.markdown(f"- **{key.replace('_', ' ').title()}**: {value}")
            else:
                st.info("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö.")
            
            st.markdown("--- ")
            st.markdown("**–ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:**")
            st.json(results_package) 
        elif st.session_state.analysis_task_id:
             if st.session_state.analysis_status_message:
                st.info(st.session_state.analysis_status_message)
             # Add a manual refresh button if stuck in pending for too long
             if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –≤—Ä—É—á–Ω—É—é"):
                 st.session_state.last_polled_task_id = st.session_state.analysis_task_id # Re-enable polling
                 st.experimental_rerun()
        else:
            st.info("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")

        # ----- Chatbot Section (Temporarily Simplified/Disabled) -----
        st.divider()
        st.subheader("–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞–Ω–∞–ª–∏–∑–∞ (AI –ê–≥–µ–Ω—Ç)")
        st.info("–ß–∞—Ç-–±–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—É–¥–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∞–Ω –ø–æ—Å–ª–µ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç API.")
        # ... (rest of the simplified chatbot UI) ...

    # --- End Section: Portfolio Analysis ---

    # –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞–º–∏ –∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏
    elif st.session_state.active_page == "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞–º–∏":
        render_transactions_manager(st.session_state.username, price_data_global, assets)
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ app_pages.py
    elif st.session_state.active_page == "Dashboard":
        # Ensure all necessary data is passed to render_dashboard
        # price_data_global, model_returns_global, model_actions_global are from load_app_data()
        # assets is derived from price_data_global.columns or st.session_state.assets
        auth_headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
        available_assets_list = st.session_state.get("all_available_tickers", []) # from load_app_data
        render_dashboard(st.session_state.username, BACKEND_API_URL, auth_headers, available_assets_list)
    
    elif st.session_state.active_page == "Portfolio Optimization":
        render_portfolio_optimization(st.session_state.username, price_data_global, assets)
    
    elif st.session_state.active_page == "Model Training":
        render_model_training(st.session_state.username, price_data_global, assets)
    
    elif st.session_state.active_page == "Model Comparison":
        render_model_comparison(st.session_state.username, model_returns_global, model_actions_global, price_data_global)
    
    elif st.session_state.active_page == "Backtest Results":
        render_backtest(st.session_state.username, model_returns_global, price_data_global)
    
    elif st.session_state.active_page == "About":
        render_about()

    # <<< Add block for the new Recommendations page >>>
    elif st.session_state.active_page == "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏":
        st.header("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        st.markdown("–ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –∞–∫—Ç–∏–≤–æ–≤ –¥–ª—è –≤–∞—à–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è.")

        # --- Session state initialization for this page ---
        if 'reco_portfolio_id' not in st.session_state: st.session_state.reco_portfolio_id = None
        if 'reco_task_id' not in st.session_state: st.session_state.reco_task_id = None
        if 'reco_results' not in st.session_state: st.session_state.reco_results = None
        if 'reco_status_message' not in st.session_state: st.session_state.reco_status_message = ""
        if 'reco_error' not in st.session_state: st.session_state.reco_error = None
        if 'last_polled_reco_task_id' not in st.session_state: st.session_state.last_polled_reco_task_id = None

        # --- Get current user's portfolio ID (similar to Analysis page) --- 
        if st.session_state.reco_portfolio_id is None and "access_token" in st.session_state:
            headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
            try:
                response = requests.get(f"{BACKEND_API_URL}/portfolios/", headers=headers, params={"limit": 1})
                response.raise_for_status()
                portfolios = response.json()
                if portfolios and len(portfolios) > 0:
                    st.session_state.reco_portfolio_id = portfolios[0].get("id")
                    st.session_state.reco_status_message = f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –≤–∞—à–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è ID: {st.session_state.reco_portfolio_id}"
                else:
                    st.session_state.reco_status_message = "–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Ä—Ç—Ñ–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π. –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –ø–æ—Ä—Ç—Ñ–µ–ª—å."
                    st.session_state.reco_portfolio_id = "ERROR_NO_PORTFOLIO" # Special value
            except requests.exceptions.RequestException as e:
                st.session_state.reco_error = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å ID –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}"
        
        if st.session_state.reco_portfolio_id and st.session_state.reco_portfolio_id != "ERROR_NO_PORTFOLIO":
            st.info(st.session_state.reco_status_message)
        elif st.session_state.reco_portfolio_id == "ERROR_NO_PORTFOLIO":
            st.warning(st.session_state.reco_status_message)
        elif not "access_token" in st.session_state:
            st.warning("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.")
        else:
            st.warning(st.session_state.reco_error or "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")

        # --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ) ---
        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        
        custom_params_json = st.text_area(
            "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±—ç–∫–µ–Ω–¥–∞ (JSON, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
            value='''{
  "risk_profile": "moderate",
  "target_return_annual_pct": 15.0,
  "drl_model_name": "PPO" 
}''',
            height=120,
            help="–≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±—É–¥—É—Ç –ø–µ—Ä–µ–¥–∞–Ω—ã –≤ Celery –∑–∞–¥–∞—á—É –∫–∞–∫ `recommendation_parameters`."
        )

        # --- –ö–Ω–æ–ø–∫–∞ –ó–∞–ø—É—Å–∫–∞ ---
        run_button_disabled = not (st.session_state.reco_portfolio_id and st.session_state.reco_portfolio_id != "ERROR_NO_PORTFOLIO")
        
        if st.button("üí° –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ", use_container_width=True, disabled=run_button_disabled):
            st.session_state.reco_task_id = None 
            st.session_state.reco_results = None
            st.session_state.reco_error = None
            st.session_state.last_polled_reco_task_id = None
            st.session_state.reco_status_message = "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π..."

            parsed_custom_params = {}
            if custom_params_json.strip(): # Check if not empty or just whitespace
                try:
                    parsed_custom_params = json.loads(custom_params_json)
                except json.JSONDecodeError as e:
                    st.session_state.reco_error = f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}"
                    # st.experimental_rerun() # Avoid immediate rerun on parse error, let user fix
            
            if not st.session_state.reco_error: # Proceed if JSON is valid or empty
                headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
                payload = {
                    # portfolio_id will be derived by backend from current_user for /recommendations/rebalance
                    # "portfolio_id": st.session_state.reco_portfolio_id, 
                    "recommendation_parameters": parsed_custom_params 
                }
                try:
                    response = requests.post(f"{BACKEND_API_URL}/recommendations/rebalance", json=payload, headers=headers)
                    response.raise_for_status()
                    task_info = response.json()
                    st.session_state.reco_task_id = task_info.get("task_id")
                    st.session_state.last_polled_reco_task_id = st.session_state.reco_task_id
                    st.session_state.reco_status_message = f"–ó–∞–ø—Ä–æ—Å –Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω. ID –ó–∞–¥–∞—á–∏: {st.session_state.reco_task_id}. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞..."
                    st.success(st.session_state.reco_status_message)
                    st.experimental_rerun() 
                except requests.exceptions.HTTPError as http_err:
                    error_detail = http_err.response.json().get("detail") if http_err.response else str(http_err)
                    st.session_state.reco_error = f"HTTP –æ—à–∏–±–∫–∞: {http_err.response.status_code} - {error_detail}"
                except requests.exceptions.RequestException as req_err:
                    st.session_state.reco_error = f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {req_err}"
                except Exception as e:
                    st.session_state.reco_error = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"
        
        # Polling for task status (similar to analysis page)
        if st.session_state.reco_task_id and st.session_state.reco_task_id == st.session_state.last_polled_reco_task_id and st.session_state.reco_results is None and st.session_state.reco_error is None:
            # Added a small visual cue for polling
            with st.spinner(f"–û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏ {st.session_state.reco_task_id}..."):
                time.sleep(3) 
                headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
                try:
                    status_response = requests.get(f"{BACKEND_API_URL}/utils/tasks/{st.session_state.reco_task_id}", headers=headers)
                    status_response.raise_for_status()
                    task_status_data = status_response.json()
                    status = task_status_data.get("status")
                    result = task_status_data.get("result") 
                    meta_info = task_status_data.get("meta", {})

                    if status == "SUCCESS":
                        st.session_state.reco_status_message = "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!"
                        st.session_state.reco_results = result 
                        st.session_state.last_polled_reco_task_id = None 
                        st.experimental_rerun() # Rerun to display results and clear spinner
                    elif status == "FAILURE" or status == "REVOKED":
                        err_msg = meta_info.get('exc_message', '–ù–µ—Ç –¥–µ—Ç–∞–ª–µ–π')
                        if isinstance(result, dict) and 'error' in result: err_msg = result['error']
                        elif isinstance(result, str) : err_msg = result
                        st.session_state.reco_error = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–°—Ç–∞—Ç—É—Å: {status}). –î–µ—Ç–∞–ª–∏: {err_msg}"
                        st.session_state.last_polled_reco_task_id = None
                        st.experimental_rerun()
                    elif status == "PROGRESS":
                        current_step = meta_info.get('current', '')
                        total_steps = meta_info.get('total', '')
                        step_status = meta_info.get('status', '–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è...')
                        st.session_state.reco_status_message = f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {step_status} ({current_step}/{total_steps})"
                        st.experimental_rerun() 
                    else: 
                        st.session_state.reco_status_message = f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {status}. {meta_info.get('status', '–û–∂–∏–¥–∞–Ω–∏–µ...')}"
                        st.experimental_rerun() 
                except requests.exceptions.RequestException as req_err:
                    st.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {req_err}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                    st.experimental_rerun()
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                    st.experimental_rerun()
        
        # Display status or results
        if st.session_state.reco_error:
            st.error(st.session_state.reco_error)
        elif st.session_state.reco_results:
            st.subheader("–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            st.json(st.session_state.reco_results) 
            
            # Example of more structured display (can be customized based on actual backend response)
            if isinstance(st.session_state.reco_results, dict):
                if "target_allocation_pct" in st.session_state.reco_results:
                    st.markdown("#### –¶–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–æ–≤:")
                    alloc_data = st.session_state.reco_results["target_allocation_pct"]
                    if isinstance(alloc_data, dict):
                        alloc_df = pd.DataFrame(list(alloc_data.items()), columns=['–ê–∫—Ç–∏–≤', '–î–æ–ª—è (%)'])
                        # alloc_df["–î–æ–ª—è (%)"] = alloc_df["–î–æ–ª—è (%)"] * 100 # Assuming backend sends as fraction, convert to %
                        st.dataframe(alloc_df.style.format({"–î–æ–ª—è (%)": "{:.2f}%"}))
                        
                        fig_pie = px.pie(alloc_df, values="–î–æ–ª—è (%)", names="–ê–∫—Ç–∏–≤", title="–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", hole=0.3)
                        fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                        st.plotly_chart(fig_pie, use_container_width=True)
                    else:
                        st.markdown("–î–∞–Ω–Ω—ã–µ –ø–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –∞–∫—Ç–∏–≤–æ–≤ –∏–º–µ—é—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.")
                
                if "summary" in st.session_state.reco_results:
                    st.markdown("#### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ—Ç —Å–∏—Å—Ç–µ–º—ã:")
                    st.info(st.session_state.reco_results["summary"])
                
                if "next_rebalance_date" in st.session_state.reco_results:
                    st.markdown(f"**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–∞—Ç–∞ —Å–ª–µ–¥—É—é—â–µ–π —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:** {st.session_state.reco_results['next_rebalance_date']}")

        elif st.session_state.reco_task_id:
             if st.session_state.reco_status_message:
                st.info(st.session_state.reco_status_message)
             if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤—Ä—É—á–Ω—É—é"):
                 st.session_state.last_polled_reco_task_id = st.session_state.reco_task_id
                 st.experimental_rerun()
        elif not run_button_disabled:
            st.info("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ) –∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.")
        

    # <<< Add block for the new Data & Analysis page >>>
    elif st.session_state.active_page == "–î–∞–Ω–Ω—ã–µ –∏ –ê–Ω–∞–ª–∏–∑":
        st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –∏ –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞")
        # Keep the existing "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤" and "–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞" (plots) sections as is for now.
        # We will focus on "–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∞–∫—Ç–∏–≤—É" and "–ß–∞—Ç –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º".

        # --- Existing code for data update and market plots ---
        # (Assuming this part remains unchanged for this refactoring task)
        st.subheader("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤")
        if 'last_update_status' not in st.session_state: st.session_state.last_update_status = None
        if 'last_update_time' not in st.session_state: st.session_state.last_update_time = None
        if 'update_counter' not in st.session_state: st.session_state.update_counter = 0
        # ... (rest of the data update UI and logic - assumed to be kept) ...
        # Example: if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ" ...): ...
        # st.markdown("--- ")
        # st.subheader("–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞")
        # with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö..."):
        #      combined_df = load_combined_data_cached(st.session_state.update_counter)
        # ... (rest of the market analysis plots: normalized, correlation, single asset - assumed to be kept) ...
        # --- End of existing code to keep ---

        st.markdown("---") # Separator before News Analysis section
        st.subheader(f"–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∞–∫—Ç–∏–≤—É (—á–µ—Ä–µ–∑ API)")

        # --- Initialize session state for API-based news analysis --- 
        if 'news_api_asset_ticker' not in st.session_state: st.session_state.news_api_asset_ticker = None
        if 'news_api_task_id' not in st.session_state: st.session_state.news_api_task_id = None
        if 'news_api_results' not in st.session_state: st.session_state.news_api_results = None # This will store results from /news/asset/{ticker} or task result
        if 'news_api_status_message' not in st.session_state: st.session_state.news_api_status_message = ""
        if 'news_api_error' not in st.session_state: st.session_state.news_api_error = None
        if 'last_polled_news_api_task_id' not in st.session_state: st.session_state.last_polled_news_api_task_id = None
        if 'news_chat_history_api' not in st.session_state: st.session_state.news_chat_history_api = []
        if 'news_chat_task_id' not in st.session_state: st.session_state.news_chat_task_id = None
        if 'news_chat_error' not in st.session_state: st.session_state.news_chat_error = None

        # --- Asset Selection --- 
        # Use all_available_tickers from session state, loaded by load_app_data()
        available_tickers_for_news = st.session_state.get("all_available_tickers", [])
        if not available_tickers_for_news:
            st.warning("–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤ –ø—É—Å—Ç. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ API.")
            # You might want to add a button to trigger load_app_data() again or guide the user.
        
        col1_news_opts, col2_news_opts = st.columns([2, 3])
        with col1_news_opts:
            selected_asset_ticker_news_api = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ç–∏–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π:", 
                options=available_tickers_for_news,
                key="news_api_asset_select",
                index=available_tickers_for_news.index(st.session_state.news_api_asset_ticker) if st.session_state.news_api_asset_ticker and st.session_state.news_api_asset_ticker in available_tickers_for_news else 0,
                on_change=lambda: st.session_state.update({
                    'news_api_task_id': None, 
                    'news_api_results': None, 
                    'news_api_error': None,
                    'last_polled_news_api_task_id': None,
                    'news_chat_history_api': [],
                    'news_chat_task_id': None,
                    'news_chat_error': None
                })
            )
            if selected_asset_ticker_news_api:
                 st.session_state.news_api_asset_ticker = selected_asset_ticker_news_api
        
        with col2_news_opts:
            today_date_news = datetime.now().date()
            news_start_date_api = st.date_input("–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π", value=today_date_news - timedelta(days=7), max_value=today_date_news, key="news_api_start_date")
            news_end_date_api = st.date_input("–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π", value=today_date_news, min_value=news_start_date_api, max_value=today_date_news, key="news_api_end_date")
            num_articles_api = st.number_input("–ú–∞–∫—Å. –∫–æ–ª-–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", min_value=1, max_value=100, value=20, step=5, key="news_api_num_articles")

        # --- Buttons for Fetching Last Analysis & Triggering New Analysis ---
        col1_buttons, col2_buttons = st.columns(2)
        with col1_buttons:
            if st.button("üîç –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑ (–∏–∑ –ë–î)", key="fetch_last_news_analysis_button", disabled=not selected_asset_ticker_news_api):
                st.session_state.news_api_task_id = None # Clear any pending task
                st.session_state.news_api_results = None
                st.session_state.news_api_error = None
                st.session_state.news_chat_history_api = []
                st.session_state.news_api_status_message = f"–ó–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {selected_asset_ticker_news_api}..."
                with st.spinner(st.session_state.news_api_status_message):
                    headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
                    try:
                        response = requests.get(f"{BACKEND_API_URL}/news/asset/{selected_asset_ticker_news_api}", headers=headers)
                        response.raise_for_status()
                        st.session_state.news_api_results = response.json()
                        st.session_state.news_api_status_message = "–ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω."
                        st.success(st.session_state.news_api_status_message)
                        # Populate chat with a summary from these results if desired
                    except requests.exceptions.HTTPError as http_err:
                        if http_err.response.status_code == 404:
                            st.session_state.news_api_status_message = f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è {selected_asset_ticker_news_api} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑."
                            st.info(st.session_state.news_api_status_message)
                        else:
                            error_detail = http_err.response.json().get("detail") if http_err.response else str(http_err)
                            st.session_state.news_api_error = f"HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {http_err.response.status_code} - {error_detail}"
                    except requests.exceptions.RequestException as req_err:
                        st.session_state.news_api_error = f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {req_err}"
                    except Exception as e:
                        st.session_state.news_api_error = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"
        
        with col2_buttons:
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π (—á–µ—Ä–µ–∑ API)", key="run_new_news_analysis_button", disabled=not selected_asset_ticker_news_api):
                st.session_state.news_api_task_id = None 
                st.session_state.news_api_results = None
                st.session_state.news_api_error = None
                st.session_state.last_polled_news_api_task_id = None
                st.session_state.news_chat_history_api = []
                st.session_state.news_api_status_message = f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {selected_asset_ticker_news_api}..."

                analysis_params_for_backend = {
                    "start_date": news_start_date_api.isoformat(),
                    "end_date": news_end_date_api.isoformat(),
                    "max_articles": num_articles_api,
                    # Add other relevant parameters for the backend task, e.g., news_sources, language
                }
                payload = {
                    "asset_ticker": selected_asset_ticker_news_api,
                    "analysis_parameters": analysis_params_for_backend
                }
                headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
                try:
                    response = requests.post(f"{BACKEND_API_URL}/news/analyze", json=payload, headers=headers)
                    response.raise_for_status()
                    task_info = response.json()
                    st.session_state.news_api_task_id = task_info.get("task_id")
                    st.session_state.last_polled_news_api_task_id = st.session_state.news_api_task_id
                    st.session_state.news_api_status_message = f"–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–ø—É—â–µ–Ω. ID –ó–∞–¥–∞—á–∏: {st.session_state.news_api_task_id}. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞..."
                    st.success(st.session_state.news_api_status_message)
                    st.experimental_rerun()
                except requests.exceptions.HTTPError as http_err:
                    error_detail = http_err.response.json().get("detail") if http_err.response else str(http_err)
                    st.session_state.news_api_error = f"HTTP –æ—à–∏–±–∫–∞: {http_err.response.status_code} - {error_detail}"
                except requests.exceptions.RequestException as req_err:
                    st.session_state.news_api_error = f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {req_err}"
                except Exception as e:
                    st.session_state.news_api_error = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"

        # Polling for task status (for news analysis task)
        if st.session_state.news_api_task_id and st.session_state.news_api_task_id == st.session_state.last_polled_news_api_task_id and st.session_state.news_api_results is None and st.session_state.news_api_error is None:
            with st.spinner(f"–û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (–ó–∞–¥–∞—á–∞: {st.session_state.news_api_task_id})..."):
                time.sleep(3) 
                headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
                try:
                    status_response = requests.get(f"{BACKEND_API_URL}/utils/tasks/{st.session_state.news_api_task_id}", headers=headers)
                    status_response.raise_for_status()
                    task_status_data = status_response.json()
                    status = task_status_data.get("status")
                    result = task_status_data.get("result") 
                    meta_info = task_status_data.get("meta", {})

                    if status == "SUCCESS":
                        st.session_state.news_api_status_message = "–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!"
                        st.session_state.news_api_results = result 
                        st.session_state.last_polled_news_api_task_id = None 
                        st.experimental_rerun()
                    elif status == "FAILURE" or status == "REVOKED":
                        err_msg = meta_info.get('exc_message', '–ù–µ—Ç –¥–µ—Ç–∞–ª–µ–π')
                        if isinstance(result, dict) and 'error' in result: err_msg = result['error']
                        elif isinstance(result, str) : err_msg = result
                        st.session_state.news_api_error = f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (–°—Ç–∞—Ç—É—Å: {status}). –î–µ—Ç–∞–ª–∏: {err_msg}"
                        st.session_state.last_polled_news_api_task_id = None
                        st.experimental_rerun()
                    elif status == "PROGRESS":
                        current_step = meta_info.get('current', '')
                        total_steps = meta_info.get('total', '')
                        step_status = meta_info.get('status', '–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è...')
                        st.session_state.news_api_status_message = f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {step_status} ({current_step}/{total_steps})"
                        st.experimental_rerun() 
                    else: 
                        st.session_state.news_api_status_message = f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {status}. {meta_info.get('status', '–û–∂–∏–¥–∞–Ω–∏–µ...')}"
                        st.experimental_rerun() 
                except requests.exceptions.RequestException as req_err:
                    st.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {req_err}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                    st.experimental_rerun()
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                    st.experimental_rerun()
        
        # --- Display News Analysis Results --- 
        if st.session_state.news_api_error:
            st.error(st.session_state.news_api_error)
        elif st.session_state.news_api_results:
            st.markdown("---")
            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {st.session_state.news_api_results.get('asset_ticker', selected_asset_ticker_news_api)}")
            results_data = st.session_state.news_api_results
            # Expected structure from backend (either from /news/asset/{ticker} or Celery task result for NewsAnalysisResultPublic)
            # { "asset_ticker": "...", "analysis_timestamp": "...", "news_count": ..., 
            #   "overall_sentiment_label": "...", "overall_sentiment_score": ..., 
            #   "key_themes": ["theme1", "theme2"], "full_summary": "...", "analysis_parameters": {...} }
            
            st.markdown(f"**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {results_data.get('analysis_timestamp', 'N/A')}")
            st.markdown(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π:** {results_data.get('news_count', 'N/A')}")
            
            col_sent_label, col_sent_score = st.columns(2)
            with col_sent_label:
                st.metric("–û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å", results_data.get('overall_sentiment_label', 'N/A'))
            with col_sent_score:
                score = results_data.get('overall_sentiment_score')
                st.metric("–û—Ü–µ–Ω–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏", f"{score:.2f}" if isinstance(score, float) else 'N/A',
                          help="-1 (–ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è) –¥–æ +1 (–ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è)")
            
            if results_data.get('key_themes'):
                st.markdown("**–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã:**")
                # st.write(", ".join(results_data['key_themes']))
                for theme in results_data['key_themes']:
                    st.markdown(f"- {theme}")
            
            if results_data.get('full_summary'):
                st.markdown("**AI –°–≤–æ–¥–∫–∞:**")
                st.info(results_data['full_summary'])
            
            # Optionally, display raw parameters or individual news items if backend provides them
            # st.expander("–î–µ—Ç–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ (—Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç API)").json(results_data)

            # --- Auto-populate chat with a summary from these results ---
            if not st.session_state.news_chat_history_api: # Only if chat is empty
                summary_for_chat = results_data.get('full_summary', "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
                if results_data.get('overall_sentiment_label'):
                    summary_for_chat = f"–ê–Ω–∞–ª–∏–∑ –¥–ª—è {results_data.get('asset_ticker')}: –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å - {results_data.get('overall_sentiment_label')} (–û—Ü–µ–Ω–∫–∞: {results_data.get('overall_sentiment_score', 0):.2f}). " + summary_for_chat
                st.session_state.news_chat_history_api.append({"role": "assistant", "content": summary_for_chat})

        elif st.session_state.news_api_task_id:
             if st.session_state.news_api_status_message:
                st.info(st.session_state.news_api_status_message)
             if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –≤—Ä—É—á–Ω—É—é"):
                 st.session_state.last_polled_news_api_task_id = st.session_state.news_api_task_id
                 st.experimental_rerun()
        elif selected_asset_ticker_news_api: # No task, no results, but asset selected
            st.info(f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –∞–∫—Ç–∏–≤–∞ {selected_asset_ticker_news_api}: –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—ã–π.")
        
        # --- News Chat Interface (API based) ---
        st.markdown("---")
        st.subheader(f"AI –ß–∞—Ç –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º –¥–ª—è {selected_asset_ticker_news_api if selected_asset_ticker_news_api else '–∞–∫—Ç–∏–≤–∞'}")

        # Display chat messages
        chat_container = st.container(height=300)
        with chat_container:
            for message in st.session_state.news_chat_history_api:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
        
        if prompt := st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –Ω–æ–≤–æ—Å—Ç–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É...", key="news_chat_api_input", disabled=not selected_asset_ticker_news_api):
            st.session_state.news_chat_history_api.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
            
            st.session_state.news_chat_task_id = None # Reset previous task ID for chat
            st.session_state.news_chat_error = None

            with st.spinner("AI –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∞—à –∑–∞–ø—Ä–æ—Å... (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)"): 
                headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
                # Construct payload for news chat API
                # Context could be the news_api_results or just the ticker
                chat_payload = {
                    "asset_ticker": selected_asset_ticker_news_api,
                    "user_query": prompt,
                    "chat_history": st.session_state.news_chat_history_api[:-1], # Send history excluding current user prompt
                    "analysis_context": st.session_state.news_api_results # Send current analysis results as context
                }
                try:
                    response = requests.post(f"{BACKEND_API_URL}/news/chat", json=chat_payload, headers=headers)
                    response.raise_for_status()
                    chat_task_info = response.json()
                    st.session_state.news_chat_task_id = chat_task_info.get("task_id")

                    # Start polling for chat task result
                    ai_response_content = None
                    polling_attempts = 0
                    max_polling_attempts = 20 # Approx 1 minute (20 * 3s)
                    
                    while polling_attempts < max_polling_attempts and ai_response_content is None:
                        time.sleep(3)
                        status_response = requests.get(f"{BACKEND_API_URL}/utils/tasks/{st.session_state.news_chat_task_id}", headers=headers)
                        status_response.raise_for_status()
                        task_status_data = status_response.json()
                        status = task_status_data.get("status")
                        result = task_status_data.get("result")

                        if status == "SUCCESS":
                            ai_response_content = result.get("ai_response", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI.") if isinstance(result, dict) else "–û—Ç–≤–µ—Ç AI –≤ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."
                            break
                        elif status == "FAILURE" or status == "REVOKED":
                            st.session_state.news_chat_error = f"–û—à–∏–±–∫–∞ –∑–∞–¥–∞—á–∏ AI —á–∞—Ç–∞ (–°—Ç–∞—Ç—É—Å: {status}). {result}"
                            break 
                        # Add slight delay for PENDING/PROGRESS before next attempt
                        polling_attempts += 1
                    
                    if ai_response_content:
                        st.session_state.news_chat_history_api.append({"role": "assistant", "content": ai_response_content})
                    elif not st.session_state.news_chat_error:
                        st.session_state.news_chat_error = "AI –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –≤–æ–≤—Ä–µ–º—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                    
                    if st.session_state.news_chat_error: # Display error if any
                         st.session_state.news_chat_history_api.append({"role": "assistant", "content": f"(–û—à–∏–±–∫–∞: {st.session_state.news_chat_error})"})
                    
                    st.experimental_rerun() # Rerun to display AI response or error

                except requests.exceptions.HTTPError as http_err:
                    error_detail = http_err.response.json().get("detail") if http_err.response else str(http_err)
                    st.session_state.news_chat_history_api.append({"role": "assistant", "content": f"(HTTP –æ—à–∏–±–∫–∞ —á–∞—Ç–∞: {http_err.response.status_code} - {error_detail})"})
                    st.experimental_rerun()
                except requests.exceptions.RequestException as req_err:
                    st.session_state.news_chat_history_api.append({"role": "assistant", "content": f"(–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —á–∞—Ç–æ–º: {req_err})"}) 
                    st.experimental_rerun()
                except Exception as e:
                    st.session_state.news_chat_history_api.append({"role": "assistant", "content": f"(–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ —á–∞—Ç–∞: {e})"}) 
                    st.experimental_rerun()
        
        # Old news analysis and chat code is now fully replaced by the API-driven version above.
        # Remove or comment out the old section:
        # # <<< START NEW: FinNLP Analysis Section >>>
        # ... (old code was here) ...
        # # <<< END NEW: FinNLP Analysis Section >>>

    # --- NEW PAGE: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (Hypothetical Portfolio Simulation) ---
    elif st.session_state.active_page == "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ":
        st.header("–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        st.markdown("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∏ —Ä–∏—Å–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.")

        # --- Session state initialization for this page ---
        if 'hypothetical_sim_task_id' not in st.session_state: st.session_state.hypothetical_sim_task_id = None
        if 'hypothetical_sim_results' not in st.session_state: st.session_state.hypothetical_sim_results = None
        if 'hypothetical_sim_status_message' not in st.session_state: st.session_state.hypothetical_sim_status_message = ""
        if 'hypothetical_sim_error' not in st.session_state: st.session_state.hypothetical_sim_error = None
        if 'last_polled_hypothetical_sim_task_id' not in st.session_state: st.session_state.last_polled_hypothetical_sim_task_id = None

        # --- –§–æ—Ä–º–∞ –¥–ª—è –≤–≤–æ–¥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ---
        with st.form("hypothetical_simulation_form"):
            st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
            
            col1_hs, col2_hs = st.columns(2)
            with col1_hs:
                hs_initial_capital = st.number_input("–ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª (USD)", min_value=1.0, value=10000.0, step=100.0, format="%.2f", key="hs_initial_capital")
                hs_start_date = st.date_input("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞", value=datetime.now().date() - timedelta(days=365), key="hs_start_date")
                hs_rebalancing_frequency = st.selectbox(
                    "–ß–∞—Å—Ç–æ—Ç–∞ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏",
                    options=["none", "monthly", "quarterly", "annually"],
                    index=0,
                    key="hs_rebalancing_frequency"
                )

            with col2_hs:
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤ JSON
                available_tickers_for_sim = st.session_state.get("all_available_tickers", ["BTCUSDT", "ETHUSDT", "SOLUSDT"])
                example_assets_weights_json = json.dumps({ticker: round(1/len(available_tickers_for_sim), 2) for ticker in available_tickers_for_sim[:3]}, indent=2) if available_tickers_for_sim else '{ "BTCUSDT": 0.5, "ETHUSDT": 0.5 }'
                
                hs_assets_weights_json = st.text_area(
                    "–í–µ—Å–∞ –∞–∫—Ç–∏–≤–æ–≤ (JSON —Ñ–æ—Ä–º–∞—Ç, —Å—É–º–º–∞ –≤–µ—Å–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å ~1.0)",
                    value=example_assets_weights_json,
                    height=150,
                    key="hs_assets_weights_json",
                    help='–ü—Ä–∏–º–µ—Ä: {"BTCUSDT": 0.6, "ETHUSDT": 0.4}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–∏–∫–µ—Ä—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç.'
                )
                hs_end_date = st.date_input("–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è", value=datetime.now().date(), key="hs_end_date")
                hs_commission_rate = st.number_input("–ö–æ–º–∏—Å—Å–∏—è –∑–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é (–¥–æ–ª—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, 0.001 –¥–ª—è 0.1%)", min_value=0.0, max_value=0.1, value=0.001, step=0.0001, format="%.4f", key="hs_commission_rate")

            hs_submit_button = st.form_submit_button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ")

        if hs_submit_button:
            st.session_state.hypothetical_sim_task_id = None
            st.session_state.hypothetical_sim_results = None
            st.session_state.hypothetical_sim_error = None
            st.session_state.last_polled_hypothetical_sim_task_id = None
            st.session_state.hypothetical_sim_status_message = "–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ..."

            try:
                assets_weights = json.loads(hs_assets_weights_json)
                if not isinstance(assets_weights, dict) or not all(isinstance(k, str) and isinstance(v, (int, float)) for k, v in assets_weights.items()):
                    raise json.JSONDecodeError("–í–µ—Å–∞ –∞–∫—Ç–∏–≤–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º {—Ç–∏–∫–µ—Ä: –≤–µ—Å}", hs_assets_weights_json, 0)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Decimal –¥–ª—è Pydantic, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –Ω–æ FastAPI –¥–æ–ª–∂–µ–Ω —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å float
                # assets_weights_decimal = {k: Decimal(str(v)) for k, v in assets_weights.items()}

                payload = {
                    "initial_capital": float(hs_initial_capital),
                    "assets_weights": assets_weights, # FastAPI/Pydantic —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç float –≤ Decimal, –µ—Å–ª–∏ –≤ —Å—Ö–µ–º–µ Decimal
                    "start_date": hs_start_date.isoformat(),
                    "end_date": hs_end_date.isoformat(),
                    "rebalancing_frequency": hs_rebalancing_frequency,
                    "commission_rate": float(hs_commission_rate)
                }

                if "access_token" not in st.session_state:
                    st.session_state.hypothetical_sim_error = "–û—à–∏–±–∫–∞: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω."
                else:
                    headers = {"Authorization": f"Bearer {st.session_state.access_token}"}
                    response = requests.post(f"{BACKEND_API_URL}/portfolios/simulate_hypothetical", json=payload, headers=headers)
                    response.raise_for_status()
                    task_info = response.json()
                    st.session_state.hypothetical_sim_task_id = task_info.get("task_id")
                    st.session_state.last_polled_hypothetical_sim_task_id = st.session_state.hypothetical_sim_task_id
                    st.session_state.hypothetical_sim_status_message = f"–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ. ID –ó–∞–¥–∞—á–∏: {st.session_state.hypothetical_sim_task_id}. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞..."
                    st.success(st.session_state.hypothetical_sim_status_message)
                    st.experimental_rerun()

            except json.JSONDecodeError as e:
                st.session_state.hypothetical_sim_error = f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –¥–ª—è –≤–µ—Å–æ–≤ –∞–∫—Ç–∏–≤–æ–≤: {e}"
            except requests.exceptions.HTTPError as http_err:
                error_detail = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏."
                try:
                    error_detail = http_err.response.json().get("detail", str(http_err))
                except json.JSONDecodeError:
                    error_detail = http_err.response.text if http_err.response.text else str(http_err)
                st.session_state.hypothetical_sim_error = f"HTTP –æ—à–∏–±–∫–∞: {http_err.response.status_code} - {error_detail}"
            except requests.exceptions.RequestException as req_err:
                st.session_state.hypothetical_sim_error = f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {req_err}"
            except Exception as e:
                st.session_state.hypothetical_sim_error = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"
                traceback.print_exc()

        # Polling for task status
        if st.session_state.hypothetical_sim_task_id and \
           st.session_state.hypothetical_sim_task_id == st.session_state.last_polled_hypothetical_sim_task_id and \
           st.session_state.hypothetical_sim_results is None and \
           st.session_state.hypothetical_sim_error is None:
            
            with st.spinner(f"–û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–ó–∞–¥–∞—á–∞: {st.session_state.hypothetical_sim_task_id})..."):
                time.sleep(3) # Wait before polling
                headers = {"Authorization": f"Bearer {st.session_state.access_token}"} if "access_token" in st.session_state else {}
                try:
                    status_response = requests.get(f"{BACKEND_API_URL}/utils/tasks/{st.session_state.hypothetical_sim_task_id}", headers=headers)
                    status_response.raise_for_status()
                    task_status_data = status_response.json()
                    status = task_status_data.get("status")
                    result = task_status_data.get("result") 
                    meta_info = task_status_data.get("meta", {})

                    if status == "SUCCESS":
                        st.session_state.hypothetical_sim_status_message = "–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
                        st.session_state.hypothetical_sim_results = result 
                        st.session_state.last_polled_hypothetical_sim_task_id = None # Stop polling
                        st.experimental_rerun()
                    elif status == "FAILURE" or status == "REVOKED":
                        err_msg = meta_info.get('exc_message', '–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.')
                        if isinstance(result, dict) and 'error' in result: err_msg = result['error']
                        elif isinstance(result, str) : err_msg = result
                        st.session_state.hypothetical_sim_error = f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–°—Ç–∞—Ç—É—Å: {status}). –î–µ—Ç–∞–ª–∏: {err_msg}"
                        st.session_state.last_polled_hypothetical_sim_task_id = None # Stop polling
                        st.experimental_rerun()
                    elif status == "PROGRESS":
                        current_step = meta_info.get('current', '')
                        total_steps = meta_info.get('total', '')
                        step_status = meta_info.get('status', '–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è...')
                        st.session_state.hypothetical_sim_status_message = f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {step_status} ({current_step}/{total_steps})"
                        st.experimental_rerun() 
                    else: # PENDING or other states
                        st.session_state.hypothetical_sim_status_message = f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {status}. {meta_info.get('status', '–û–∂–∏–¥–∞–Ω–∏–µ...')}"
                        st.experimental_rerun() 
                except requests.exceptions.RequestException as req_err:
                    st.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {req_err}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                    st.experimental_rerun()
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {e}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞...")
                    traceback.print_exc()
                    st.experimental_rerun()
        
        # Display status or results
        if st.session_state.hypothetical_sim_error:
            st.error(st.session_state.hypothetical_sim_error)
        elif st.session_state.hypothetical_sim_results:
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
            results_package = st.session_state.hypothetical_sim_results
            
            metrics = results_package.get("metrics")
            if metrics:
                st.markdown("#### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
                
                col_m1, col_m2 = st.columns(2)
                with col_m1:
                    st.metric("–ü–µ—Ä–∏–æ–¥", metrics.get("period", "N/A"))
                    st.metric("–ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª", f"${metrics.get('initial_capital', 0):,.2f}")
                    st.metric("–ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è", f"${metrics.get('final_value_hypothetical', 0):,.2f}")
                    st.metric("CAGR (—Å—Ä–µ–¥–Ω–µ–≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å)", f"{metrics.get('cagr_hypothetical', 0)*100:.2f}%")
                with col_m2:
                    st.metric("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞", f"{metrics.get('sharpe_hypothetical', 0):.2f}")
                    st.metric("–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å", f"{metrics.get('volatility_hypothetical', 0)*100:.2f}%")
                    st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞", f"{metrics.get('max_drawdown_hypothetical', 0)*100:.2f}%")
                    st.metric("–ß–∞—Å—Ç–æ—Ç–∞ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏", str(metrics.get("rebalancing_frequency", "N/A")).title())
                    st.metric("–ö–æ–º–∏—Å—Å–∏—è", f"{metrics.get('commission_rate', 0)*100:.3f}%")

                # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ simulation_parameters, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                with st.expander("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–ª—è —Å–ø—Ä–∞–≤–∫–∏)"):
                    st.json(results_package.get("simulation_parameters", {}))
                
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫, –µ—Å–ª–∏ –±—ç–∫–µ–Ω–¥ –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ–≥–æ
                # if "plot_data" in results_package:
                #     st.subheader("–ì—Ä–∞—Ñ–∏–∫ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
                #     # ... –∫–æ–¥ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ ...
            else:
                st.info("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö.")
            
            st.markdown("---")
            st.markdown("–ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (JSON):")
            st.json(results_package)

        elif st.session_state.hypothetical_sim_task_id: # Task is running or pending
            if st.session_state.hypothetical_sim_status_message:
                st.info(st.session_state.hypothetical_sim_status_message)
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä—É—á–Ω—É—é"):
                st.session_state.last_polled_hypothetical_sim_task_id = st.session_state.hypothetical_sim_task_id # Re-enable polling for this task
                st.experimental_rerun()
        elif not hs_submit_button and not st.session_state.hypothetical_sim_task_id : # Initial state, no button pressed yet, no task running for this page
             st.info("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã—à–µ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ', —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")



    '''
    poetry run streamlit run auth_app.py
    '''