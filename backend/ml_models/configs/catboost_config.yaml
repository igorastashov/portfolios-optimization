# Hydra config for CatBoost training pipeline

defaults:
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

# General pipeline parameters
pipeline_name: "catboost_price_prediction_pipeline"
project_name: "PortfolioOptimization/PricePrediction"
queue_name: "default" # ClearML queue to use
base_docker_image: "python:3.10-slim"

# Parameters for each step (task)
data_preparation:
  task_name_prefix: "data_preparation_catboost"
  # Input dataset parameters (ClearML Dataset name/project or ID)
  input_market_data: 
    project: "PortfolioOptimization/Datasets"
    name: "market_data_binance_hourly" # Example: should match output of data_update_pipeline
    id: "" # Optional: direct ID if known, overrides project/name
  input_news_data: # Optional news data
    project: "PortfolioOptimization/Datasets"
    name: "news_data_alphavantage_aggregated" # Example
    id: ""
    enabled: true # Set to false if not using news data
  
  # Output parameters for artifacts
  # output_train_artifact_name: "train_data.parquet" # Will be {ticker}_train_data.parquet
  # output_val_artifact_name: "val_data.parquet"
  # output_test_artifact_name: "test_data.parquet"
  mean_encoding_map_artifact_name: "mean_encoding_map.json"
  categorical_features_list_artifact_name: "categorical_features_list.json"

  # Feature engineering parameters
  target_asset_ticker: "BTCUSDT" # Default, overridden by pipeline arg or loop
  target_col_name: "Close"       # Name of the target column in market_data_df
  target_horizon_hours: 192      # 8 days * 24 hours/day (from notebook: TARGET_HORIZON_DAYS = 8)
  lags_config: [1, 2, 3, 6, 12, 24, 48, 72, 96, 120, 144, 168, 192] # Example, align with notebook or desired lags
  
  # Calendar features from notebook: hour_raw, dayofweek_raw, dayofmonth, month
  # These are generated by default in the script if index is datetime
  # features_for_mean_encoding: ['hour_raw', 'dayofweek_raw'] # From notebook example (hour, dayofweek used)
  # The script used 'hour' and 'dayofweek' (not _raw versions) for mean encoding if USE_MEAN_ENCODING_FOR_HOUR was true.
  # Let's use the raw versions as the input to mean_encoding to be clear.
  features_for_mean_encoding: ['hour', 'dayofweek'] # These will be the columns from generate_calendar_features
  use_mean_encoding_for_hour: true # From notebook example

  news_cols_to_merge: ['avg_overall_sentiment', 'avg_btc_specific_sentiment', 'sum_news_count', 'Change %'] # From notebook
  # Ensure 'Change %' is a valid column name or handled appropriately.

  # Columns to drop before training (TARGET will be replaced by target_col_name)
  # 'y_model_future' and 'y_pred_naive_source' are generated in the script and then dropped.
  cols_to_drop_from_X: ["TARGET_REPLACE", "Open", "High", "Low"] 

  # Test/Validation split parameters
  test_size_ratio: 0.15
  validation_size_ratio: 0.15 # Applied to the (1 - test_size_ratio) part
  shuffle_data_before_split: false # Time series data usually shouldn't be shuffled
  
  # NaN handling
  # nan_fill_strategy: "mean" # or "median", "ffill", "bfill", or a specific value like 0
  # For now, notebook uses dropna based on y_model_future and max_lag. Will replicate this specific logic.
  # If more advanced NaN handling is needed, it can be added based on a config strategy.

  # Technical indicators config (already present in an earlier version, ensure it's still relevant)
  technical_indicators_config:
    rsi:
      enabled: true
      window: 14
    macd:
      enabled: true
      window_slow: 26
      window_fast: 12
      window_sign: 9
    bollinger:
      enabled: true
      window: 20
      window_dev: 2
    stoch:
      enabled: true
      window: 14
      smooth_window: 3
    atr:
      enabled: true
      window: 14
    obv:
      enabled: true

train_model:
  task_name_prefix: "train_catboost_model"
  # CatBoost model parameters from notebook
  catboost_model_params:
    iterations: 1000       # From notebook example, adjust as needed
    learning_rate: 0.05
    depth: 6
    l2_leaf_reg: 3
    loss_function: "RMSE"
    eval_metric: "RMSE"
    random_seed: 42
    early_stopping_rounds: 50
    # verbose: 0 # This will be set in the script
    # cat_features: [] # This will be determined by data_preparation and passed as an artifact

evaluate_model:
  task_name_prefix: "evaluate_catboost_model"
  metrics_to_log: ["MAE", "RMSE", "MAPE", "R2"]
  plot_figsize: [12, 6]
  plot_xlabel: 'Time Steps (Test Set)'
  plot_ylabel: 'Price'
  compare_with_naive_model: true
  generate_plots: true

register_model:
  task_name_prefix: "register_catboost_model"
  model_registry_name_prefix: "CatBoost_Price_Predictor" # Will append _{ticker}
  registration_threshold_metric: "MAPE" # Example, align with actual decision metric
  registration_threshold_value: 2.0     # Example, if MAPE < 2.0%
  comparison_operator: "less_than"    # "less_than" or "greater_than"
  default_stage: "Production"

# Global tags for all ClearML tasks in this pipeline
global_tags: ["catboost", "price_prediction", "crypto", "v2_notebook_logic"]

# Pipeline controller parameters (used by catboost_training_pipeline.py)
pipeline_params:
  # List of assets to run the full pipeline for
  target_asset_tickers: ["BTCUSDT", "ETHUSDT"] # Example, can be overridden by CLI
  # Whether to start the pipeline run automatically after definition
  run_pipeline_locally_after_definition: false 